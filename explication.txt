PROJECT 2 - PACMAN IMITATION LEARNING - Documentation complète


PARTIE 1 : Vue d'ensemble

   But: apprendre à Pacman à imiter un expert en utilisant l'apprentissage supervisé. 
   Depuis un dataset de paires (GameState, action)
   et on veut entraîner un réseau de neurones à prédire quelle action l'expert aurait pris.

   Ordre de lecture : ici les 5 fichiers qu'on a modifié
   1. data.py - Convertit GameState en 23 features
   2. architecture.py - Définit le réseau MLP (23 → 128 → 64 → 32 → 5)
   3. train.py - Entraîne le modèle (avec plotting.py pour les graphiques)
   4. plotting.py - Fonctions de visualisation (graphiques loss & accuracy)
   5. pacmanagent.py - Utilise le modèle pour jouer


   Quick summary de chaque fichier :

   data.py (Feature Engineering)
   La partie la plus importante. On transforme le GameState en 23 features :
   position, ghosts, food, géométrie du labyrinthe, danger, actions légales.
   Tout est normalisé pour que le réseau converge bien.
   Inspiré des techniques de prétraitement utilisées dans MNIST [5].

   architecture.py (Réseau de neurones)
   MLP simple : 23 → 128 → 64 → 32 → 5 (3 couches cachées)
   Pattern par couche : Linear → BatchNorm → GELU → Dropout(0.15)
   Architecture similaire aux MLPs classiques pour la classification (voir MNIST [5]).

   train.py (Entraînement)
   Split train/test 80/20, Adam optimizer, 32 epochs, batch_size=256.
   Utilise CrossEntropyLoss pour classification multi-classe (5 actions).
   Évaluation finale sur le test set avec calcul de l'accuracy.
   Code modulaire : imports depuis plotting.py pour les visualisations.

   plotting.py (Visualisation - nouveau fichier)
   Fonctions dédiées pour les graphiques live pendant l'entraînement.
   setup_training_plots() → initialise les figures (loss + accuracy).
   update_training_plots() → met à jour les graphiques en temps réel.
   Séparation claire : tout le code matplotlib est isolé ici.

   pacmanagent.py (Agent)
   Utilise le modèle entraîné pour jouer.
   Convertit l'état → features → forward → softmax → meilleure action légale.


   Structure du projet :
   project2/
   ├── datasets/
   │   ├── pacman_dataset.pkl    → 15018 paires (state, action) de l'expert
   │   └── pacman_test.pkl       → États de jeu sans actions pour Gradescope
   ├── pacman_module/            → Moteur de jeu (NE PAS MODIFIER)
   ├── data.py                   → Feature engineering + Dataset
   ├── architecture.py           → Réseau de neurones (MLP)
   ├── train.py                  → Boucle d'entraînement (code modulaire)
   ├── plotting.py               → Visualisation (loss & accuracy) [NOUVEAU]
   ├── pacmanagent.py            → Agent qui joue
   ├── run.py                    → Visualisation du jeu
   ├── write_submission.py       → Génération du CSV
   ├── pacman_model.pth          → Poids du modèle entraîné
   └── submission.csv            → Prédictions pour Gradescope


PARTIE 2 : Data.py - Feature Engineering

   Un réseau de neurones ne peut pas apprendre directement d'un GameState brut.
   On doit extraire des informations pertinentes pour la prise de décision.

   Nos 23 features (toutes normalisées ~[0,1]):

   POSITION PACMAN (2 features):
   [0] px / 20       Position X de Pacman
   [1] py / 20       Position Y de Pacman

   INFORMATION GHOST (4 features):
   [2] dx_ghost / 20    Direction X vers le ghost le plus proche
   [3] dy_ghost / 20    Direction Y vers le ghost
   [4] ghost_dist / 20  Distance Manhattan au ghost
   [5] ghost_adjacent   1 si ghost à distance 1 (danger immédiat!)

   INFORMATION FOOD (4 features):
   [6] n_food / 50          Nombre de food restante
   [7] dx_food / 20         Direction X vers la food la plus proche
   [8] dy_food / 20         Direction Y vers la food
   [9] closest_food / 20    Distance à la food la plus proche

   GEOMETRIE DU LABYRINTHE (5 features):
   [10] dist_north / 10  Distance au mur au Nord
   [11] dist_south / 10  Distance au mur au Sud
   [12] dist_east / 10   Distance au mur à l'Est
   [13] dist_west / 10   Distance au mur à l'Ouest
   [14] is_corner        1 si Pacman est dans un coin (≤2 directions libres)

   FEATURES DE DANGER (3 features) - Les plus importantes selon moi:
   [15] danger_level      = 1/(ghost_dist), haut quand danger proche
   [16] ghost_blocks_food = 1 si ghost entre Pacman et la food
   [17] escape_options    = nombre de directions de fuite / 4

   ACTIONS LEGALES (5 features):
   [18] legal_north  1 si NORTH est légal
   [19] legal_south  1 si SOUTH est légal
   [20] legal_east   1 si EAST est légal
   [21] legal_west   1 si WEST est légal
   [22] legal_stop   1 si STOP est légal


   Comment on trouve la food la plus proche ?

   1. On récupère toutes les positions de food
      food_positions = [(5, 3), (7, 8), (2, 4), ...]

   2. On calcule la distance Manhattan à CHAQUE food
      distances = [abs(pac_x - food_x) + abs(pac_y - food_y)
                  for food_x, food_y in food_positions]

   3. On trouve laquelle est la plus proche
      closest_index = argmin(distances)

   4. On calcule la direction vers cette food
      direction_x = closest_food_x - pac_x
      direction_y = closest_food_y - pac_y

      Si direction_x > 0 → food à droite
      Si direction_x < 0 → food à gauche
      Si direction_y > 0 → food en haut
      Si direction_y < 0 → food en bas


   Géométrie du labyrinthe

   La fonction dist_until_wall() compte combien de cases Pacman peut avancer
   dans une direction avant de rencontrer un mur.

   Exemple visuel:
      # # # # # # #
      # . . . . . #
      # # P . . . #  ← Pacman en (2,2)
      # # # . . . #
      # # # # # # #

   dist_until_wall(2, 2, 1, 0) = 3  (peut aller 3 cases à droite)
   dist_until_wall(2, 2, -1, 0) = 0  (mur immédiat à gauche)

   Détection de coin :
   On compte combien de directions sont libres autour de Pacman.
   Si ≤2, c'est un coin (dangereux car peu d'options pour fuir).


PARTIE 3 : Architecture (architecture.py)

   Pourquoi un MLP et pas un CNN ?
   Les CNN sont faits pour les images 2D où les pixels voisins sont liés (ex: MNIST [5]).
   Notre input est un vecteur (je dirais même un tenseur!) 1D de 23 features sans relation spatiale,
   donc un MLP est le bon choix - similaire aux architectures fully-connected classiques.

   Structure : 23 → 128 → 64 → 32 → 5

   Pour chaque couche cachée ici 3: Linear → BatchNorm → GELU → Dropout

   1. Linear : transforme les données (multiplication matricielle + biais)
   2. BatchNorm [1] : normalise les valeurs entre couches (stabilise l'entraînement)
   3. GELU [2] : activation smooth, meilleure que ReLU, la meilleur que j'ai trouver, testez d'autre
   4. Dropout [3] : prévient l'overfitting (p=0.15)
   5. Pas d'activation finale : CrossEntropyLoss veut des logits bruts

   Pourquoi GELU et pas ReLU ?
   GELU [2] est plus smooth (pas de coupure brutale à 0),
   meilleur flow de gradients, utilisé dans GPT et BERT.


PARTIE 4 : Entraînement (train.py) + Visualisation (plotting.py)

   Pipeline (train.py) :
   1. Charger le dataset (15018 échantillons)
   2. Split train/test (80%/20%) avec random_split
   3. Entraîner pendant 32 epochs avec visualisation
   4. Évaluer sur test set et sauvegarder le modèle

   Hyperparamètres optimisés :
   - batch_size = 256  → Augmenté pour meilleure stabilité et vitesse
   - epochs = 32       → Réduit car convergence plus rapide avec batch_size plus grand
   - lr = 1e-3         → Learning rate standard pour Adam [4]
   - test_ratio = 0.2  → 20% pour évaluation finale
   - show_every = 8    → Fréquence de visualisation des plots

   Modifications importantes :
   - Utilisation de tqdm/trange pour progression en temps réel
   - Visualisation interactive de la loss + accuracy pendant l'entraînement
   - Évaluation du test set à chaque epoch
   - Checkpointing : sauvegarde automatique du meilleur modèle basé sur test accuracy

   Architecture modulaire (nouveau design) :
   - train.py → contient UNIQUEMENT la logique d'entraînement
   - plotting.py → contient TOUTES les fonctions matplotlib
   - evaluate_model() → fonction dédiée pour évaluer l'accuracy sur le test set
   - Code PEP 8 conforme, lisible, maintenable

   Visualisation (plotting.py) :
   Deux fonctions principales qui gèrent tous les graphiques :

   1. setup_training_plots(num_plots)
      - Crée une fenêtre unique avec grille de subplots
      - Loss plots à gauche (Epoch 0, 8, 16, 24, Final)
      - Accuracy plot à droite (courbe continue)
      - Retourne (fig, axes, ax_acc)

   2. update_training_plots(axes, ax_acc, plot_idx, losses, ...)
      - Met à jour les graphiques en temps réel
      - Gère les mises à jour périodiques (toutes les 8 epochs)
      - Gère la mise à jour finale (is_final=True)
      - Refresh automatique avec plt.pause()


   Loss function : CrossEntropyLoss

   La loss mesure à quel point le réseau se trompe (0 = parfait, plus c'est grand, plus il est loin de la bonne action).
   Le gradient, c'est la dérivée de cette loss par rapport aux poids : il indique dans quelle direction et de combien on doit modifier les poids pour réduire l'erreur (descente de gradient).

   Vu au cours pour les problèmes de classification.
   Mais pourquoi on a besoin d'une "loss" ? Explications depuis le début :

            ÉTAPE 1 : Qu'est-ce qu'on veut faire ?

            On veut que le réseau apprenne à imiter l'expert.
            Pour chaque situation de jeu, l'expert a choisi une action (ex: EAST).
            On veut que le réseau apprenne à faire le même choix.

            Exemple concret :
            - État du jeu : Pacman en (5,3), ghost à droite, food en haut
            - Expert a choisi : NORTH (indice 0)
            - Réseau prédit : [2.1, 0.5, 3.2, 1.0, 0.3]  ← nombres bruts (logits)
                              ↑    ↑    ↑    ↑    ↑
                              NORTH SOUTH EAST WEST STOP

            Problème : Le réseau prédit 3.2 pour EAST, mais l'expert voulait NORTH !
            On doit dire au réseau "tu t'es trompé, il fallait choisir NORTH".

            ÉTAPE 2 : Comment mesurer l'erreur ?

            D'abord, convertir les logits en probabilités avec SOFTMAX :

            Softmax(x_i) = exp(x_i) / Σ exp(x_j)

            Logits :        [2.1,  0.5,  3.2,  1.0,  0.3]
                              ↓     ↓     ↓     ↓     ↓
            Probabilités :  [0.18, 0.04, 0.54, 0.06, 0.03]
                              ↑
                           NORTH = 18% seulement (mais c'est la bonne action!)

            Les probabilités somment à 1.0 (= 100%).
            On voit que le réseau donne seulement 18% de confiance à NORTH,
            alors que c'est l'action correcte !

            ÉTAPE 3 : Calculer la perte (loss)

            La loss mesure "à quel point le réseau s'est trompé".

            On veut pénaliser le réseau quand :
            - La probabilité de la BONNE action est FAIBLE (mauvais !)
            - La probabilité de la BONNE action est ÉLEVÉE (bon !)

            Formule mathématique (pour 1 exemple) :
               Loss = -log(probabilité_de_la_bonne_action)

            Dans notre exemple :
               Bonne action = NORTH, probabilité = 0.18
               Loss = -log(0.18) = 1.71

            Plus la probabilité est basse, plus la loss est élevée (= grosse pénalité).
            Si probabilité = 1.0 (100% sûr), alors loss = 0 (parfait !).

            ÉTAPE 4 : Cross Entropy = moyenne sur tout le batch

            Un batch = groupe de 128 exemples traités ensemble.
            On calcule la loss pour CHAQUE exemple, puis on fait la moyenne.

            Formule complète (du cours) :
               L(θ) = -1/N Σ_(x_j,y_j)∈d Σ_{i=1}^C y_ij log f_i(x_j; θ)

            Où :
            - N = nombre d'exemples dans le batch (128)
            - C = nombre de classes (5 actions)
            - y_ij = 1 si l'exemple j appartient à la classe i, 0 sinon
            - f_i(x_j; θ) = probabilité prédite par le réseau pour la classe i

            En clair : Pour chaque exemple, prends -log(proba de la bonne action),
            puis fais la moyenne sur tout le batch.

            ÉTAPE 5 : Pourquoi CrossEntropyLoss en PyTorch ?

            Manuellement, il faudrait faire :
            1. Logits → Softmax → probabilités
            2. Prendre le log des probabilités → log-probabilités
            3. Sélectionner la bonne action et calculer -log(proba)
            4. Faire la moyenne

            PyTorch fait TOUT ça automatiquement avec CrossEntropyLoss() !

            Bonus : PyTorch utilise LogSoftmax au lieu de Softmax + Log séparément.
            Pourquoi ? Pour la stabilité numérique (éviter les overflows avec exp()).

            Résumé :
               CrossEntropyLoss = Softmax + Log + Sélection + Moyenne

            En une seule ligne de code, PyTorch :
            - Convertit les logits en probabilités
            - Calcule -log(probabilité de la bonne action)
            - Fait la moyenne sur le batch
            - Tout ça de manière stable et rapide !

            C'est pour ça qu'on n'a PAS besoin de mettre Softmax à la fin du réseau :
            CrossEntropyLoss s'attend à recevoir des logits bruts et fait le reste.

   Optimizer : Adam [4]
   Adam est le choix par défaut pour le deep learning car il adapte
   le learning rate par paramètre et converge rapidement.
   Fonctionne bien avec notre architecture inspirée des MLPs classiques (MNIST [5]).

      Checkpointing - Sauvegarde du meilleur modèle :
      À chaque epoch, on évalue l'accuracy sur le test set.
      Si l'accuracy actuelle > meilleure accuracy précédente, on sauvegarde le modèle.
      Cela garantit qu'on garde le modèle qui généralise le mieux, pas le dernier
      (qui pourrait avoir overfitté). Le modèle est sauvegardé dans pacman_model.pth.


PARTIE 5 : Agent (pacmanagent.py)

   Juste lire le .py suffit


PARTIE 6 : Questions possibles à l'oral - FAQ

   Q: Pourquoi avoir séparé train.py et plotting.py ?
   R: Séparation des responsabilités (design pattern fondamental).
   train.py s'occupe UNIQUEMENT de l'entraînement (logique métier).
   plotting.py s'occupe UNIQUEMENT de la visualisation (présentation).
   Avantages : code plus lisible, testable, maintenable, réutilisable.
   Si on veut changer les graphiques, on modifie juste plotting.py.
   Code PEP 8 conforme avec lignes < 79 caractères.

   Q: Pourquoi un MLP et pas un CNN?
   R: Les CNN sont faits pour les images 2D où les pixels voisins sont liés.
   Notre input est un vecteur 1D de 23 features sans relation spatiale,
   donc un MLP est le bon choix.

   Q: Pourquoi normaliser les features?
   R: Les NN convergent mieux quand les inputs sont dans la même échelle.
   Sans normalisation, certaines features domineraient les autres.

   Q: Pourquoi GELU?
   R: Activation smooth avec meilleur flow de gradients que ReLU.
   Utilisé dans GPT, BERT. Performance empiriquement supérieure.

   Q: Pourquoi BatchNorm?
   R: Sans BatchNorm [1], l'entraînement était instable.
   BatchNorm normalise les valeurs entre couches pour stabiliser les gradients.
   Permet d'utiliser un learning rate plus élevé et convergence plus rapide.

   Q: Pourquoi CrossEntropyLoss?
   R: C'est la loss standard pour la classification multi-classe.
   Combine LogSoftmax et NLLLoss efficacement.

   Q: Pourquoi les features de danger?
   R: Le modèle avait du mal à éviter les ghosts avec juste la distance.
   danger_level donne un gradient de danger,
   ghost_blocks_food dit si le chemin vers la food est dangereux,
   escape_options dit combien de fuites sont possibles.

   Q: Comment gérer les actions illégales?
   R: On trie les prédictions par probabilité et on prend la première action
   qui est dans la liste des actions légales.

   Q: Pourquoi 32 epochs avec batch_size=256?
   R: Optimisé empiriquement. Batch size plus grand = gradients plus stables = convergence plus rapide.
   32 epochs suffisent avec batch_size=256, alors qu'il fallait 50 epochs avec batch_size=128.
   C'est un compromis vitesse/performance. 


   Q: Pourquoi normaliser ?
   R: Les réseaux de neurones fonctionnent mieux quand toutes les features
   sont dans la même échelle.
   Sans normalisation, la position X pourrait être 0-20,
   le score pourrait être -500 à +1000, les flags sont 0 ou 1...
   Avec normalisation tout est ~[0,1], ce qui accélère la convergence
   et évite que certaines features dominent les autres.

   Q: Pourquoi convertir les actions en indices ?
   R: Les réseaux de neurones ne comprennent que les nombres,
   pas les objets Python comme Directions.NORTH.
   On crée donc deux mappings :

   ACTION_TO_INDEX = {
      Directions.NORTH: 0,
      Directions.SOUTH: 1,
      Directions.EAST: 2,
      Directions.WEST: 3,
      Directions.STOP: 4
   }

   INDEX_TO_ACTION = {0: Directions.NORTH, ...}

   Pendant l'entraînement :
   Expert joue EAST → converti en indice 2 → Le réseau apprend à prédire 2

   Pendant le jeu :
   Réseau prédit [0.05, 0.1, 0.75, 0.08, 0.02] → argmax = 2 → reconverti en EAST
