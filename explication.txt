================================================================================
PROJECT 2 - PACMAN IMITATION LEARNING
Documentation compl√®te et simplifi√©e
================================================================================


TABLE DES MATI√àRES
==================

PARTIE 0 : Comment fonctionne un r√©seau de neurones ? (pour bien comprendre)
PARTIE 1 : Vue d'ensemble du projet
PARTIE 2 : Les fichiers du projet
PARTIE 3 : data.py - Transformer l'√©tat du jeu en nombres
PARTIE 4 : architecture.py - Le cerveau du r√©seau
PARTIE 5 : train.py - Apprendre au r√©seau
PARTIE 6 : write_submission.py - G√©n√©rer les pr√©dictions
PARTIE 7 : Questions fr√©quentes (FAQ)


================================================================================
PARTIE 0 : Comment fonctionne un r√©seau de neurones ?
================================================================================

Cette partie explique les bases pour bien comprendre le projet.


√âTAPE 1 : C'est quoi un r√©seau de neurones ?
---------------------------------------------

Imagine une fonction math√©matique magique : f(x) = y

- Tu donnes des informations en entr√©e (x)
- La fonction te donne une r√©ponse en sortie (y)

Exemple pour Pacman :
- ENTR√âE (x) : Position de Pacman, position du fant√¥me, o√π est la nourriture
- SORTIE (y) : Quelle direction prendre ? (NORTH, SOUTH, EAST, WEST, STOP)

Cette fonction contient des milliers de nombres appel√©s "poids" (weights).
Au d√©but, ces poids sont al√©atoires ‚Üí la fonction fait n'importe quoi.
Le but de l'entra√Ænement : ajuster ces poids pour que la fonction donne les bonnes r√©ponses.


√âTAPE 2 : Comment le r√©seau fait une pr√©diction ? (Forward Pass)
-----------------------------------------------------------------

C'est le moment o√π on demande au r√©seau : "Que dois-je faire ?"

Exemple concret :
1. x: [0.25, 0.30, 0.8, ..., 1, 0]  (23 nombres)

2. Le r√©seau fait ses calculs :
   Input (23 nombres)
     ‚Üì
   Linear ‚Üí BatchNorm ‚Üí ReLU ‚Üí Dropout
     ‚Üì
   Linear ‚Üí BatchNorm ‚Üí ReLU ‚Üí Dropout
     ‚Üì
   Linear ‚Üí BatchNorm ‚Üí ReLU ‚Üí Dropout
     ‚Üì
   Linear (derni√®re couche)
     ‚Üì
   Output : [2.1, 0.5, 3.2, 1.0, 0.3]

3. On regarde quel nombre est le plus grand :
   [2.1, 0.5, 3.2, 1.0, 0.3]
    ‚Üë    ‚Üë    ‚Üë    ‚Üë    ‚Üë
   NORTH SOUTH EAST WEST STOP

   3.2 est le plus grand ‚Üí Le r√©seau pr√©dit EAST


√âTAPE 3 : Comment mesurer si le r√©seau s'est tromp√© ? (Loss)
------------------------------------------------------------

Probl√®me : Le r√©seau a pr√©dit EAST, mais l'expert voulait NORTH !

La "loss" (perte) mesure l'erreur :
- Si le r√©seau a raison ‚Üí loss = 0 (parfait !)
- Si le r√©seau se trompe ‚Üí loss = grand nombre (mauvais !)

Comment on calcule la loss ?

1. On transforme les nombres en probabilit√©s avec Softmax :
  y= [2.1, 0.5, 3.2, 1.0, 0.3]  ‚Üí  [0.18, 0.04, 0.54, 0.06, 0.03]

   Maintenant les nombres font tous ensemble = 1.0 (100%)
   C'est comme dire : "Je suis s√ªr √† 18% que c'est NORTH, 54% que c'est EAST..."

2. On regarde la probabilit√© de la bonne action (NORTH = 0.18 = 18%)

3. On calcule la loss :
   Loss = -log(0.18) = 1.71

Plus la probabilit√© est basse, plus la loss est grande.
Si la probabilit√© √©tait 1.0 (100% s√ªr), la loss serait 0 (parfait).


√âTAPE 4 : Comment corriger les erreurs ? (Backward Pass)
--------------------------------------------------------

Maintenant qu'on sait que le r√©seau s'est tromp√© (loss = 1.71),
on veut ajuster les poids pour r√©duire cette erreur.

Question : Dans quelle direction faut-il bouger chaque poids ?
R√©ponse : Les GRADIENTS nous le disent !

Un gradient, c'est comme une fl√®che qui dit :
- "Augmente ce poids" (gradient positif)
- "Diminue ce poids" (gradient n√©gatif)
- "Ne touche pas ce poids" (gradient proche de z√©ro)

Exemple simple :
- Un poids w = 0.5
- Son gradient = -0.3
- Signification : Si j'augmente w, la loss diminue ! (c'est bien)

Le r√©seau contient 47,168 poids au total.
PyTorch calcule automatiquement le gradient de CHAQUE poids avec loss.backward().


√âTAPE 5 : Comment ajuster les poids ? (Optimizer)
-------------------------------------------------

Maintenant qu'on a les gradients, on met √† jour les poids.

IMPORTANT : Les gradients sont des MATRICES !
- La loss L = 1 nombre (scalaire)
- Les poids W = matrice (par exemple 256 √ó 23)
- Le gradient ‚àáW L = matrice de la M√äME TAILLE que W

Exemple pour Linear(23, 256) :
   W = matrice (256, 23) avec 5,888 poids
   ‚àáW = matrice (256, 23) avec 5,888 gradients

Chaque case du gradient indique :
   "Si j'augmente ce poids, est-ce que la loss augmente ou diminue ?"

   Gradient positif ‚Üí augmenter ce poids fait AUGMENTER la loss
                   ‚Üí donc on DIMINUE ce poids
   Gradient n√©gatif ‚Üí augmenter ce poids fait DIMINUER la loss
                   ‚Üí donc on AUGMENTE ce poids

Formule de base (appliqu√©e √† CHAQUE poids) :
   nouveau_poids = ancien_poids - learning_rate √ó gradient

Exemple pour UN poids :
- Ancien poids : w = 0.5
- Gradient : -0.3
- Learning rate : 0.0008
- Nouveau poids : w = 0.5 - 0.0008 √ó (-0.3) = 0.50024

Mais on fait √ßa pour les 47,168 poids du r√©seau !

On utilise Adam (optimizer intelligent) :
- Il adapte automatiquement le learning_rate pour chaque poids
- Il fait de GRANDS pas quand il est s√ªr de la direction
- Il fait de PETITS pas quand il h√©site
- R√©sultat : converge plus vite et de mani√®re plus stable


√âTAPE 6 : Le cycle complet d'entra√Ænement
-----------------------------------------

Une it√©ration d'entra√Ænement, c'est ces 4 √©tapes :

```
for epoch in range(150):                       # R√©p√©ter 150 fois
    for features, actions in loader_train:     # Pour chaque batch

        1. loss = model.loss(features, actions)
           ‚Üí Forward pass : calcule la pr√©diction et l'erreur cad loss

        2. optim.zero_grad()
           ‚Üí Efface les anciens gradients

        3. loss.backward()
           ‚Üí Backward pass : calcule les gradients

        4. optim.step()
           ‚Üí Met √† jour les poids avec les gradients
```

On r√©p√®te ce cycle 7,050 fois (150 epochs √ó 47 batches).
√Ä chaque fois, les poids s'am√©liorent un petit peu.


√âTAPE 7 : Pourquoi des batches et des epochs ?
----------------------------------------------

Batch = groupe de 256 exemples trait√©s ensemble
- Plus efficace pour le GPU
- Les gradients sont plus stables (moyenne sur 256 exemples)

Epoch = 1 passage complet sur tous les exemples (15,018 exemples)
- 1 epoch = 15,018 √∑ 256 = ~47 batches
- Le r√©seau a besoin de voir les exemples PLUSIEURS FOIS pour bien apprendre
- On fait 150 epochs pour que le r√©seau converge compl√®tement


√âTAPE 8 : O√π se trouvent les op√©rations dans le r√©seau ?
--------------------------------------------------------

C'est une question importante pour bien comprendre !

Les op√©rations (Linear, BatchNorm, ReLU, Dropout) ne sont PAS dans les neurones.
Elles se trouvent ENTRE les couches, dans les CONNEXIONS.

Visualisation :

   [Input Layer] ‚óã ‚óã ‚óã (23 neurones)
         |
         | ‚Üê ICI : Linear ‚Üí BatchNorm ‚Üí ReLU ‚Üí Dropout
         |
   [Hidden 1]    ‚óã ‚óã ‚óã ... (256 neurones)
         |
         | ‚Üê ICI : Linear ‚Üí BatchNorm ‚Üí ReLU ‚Üí Dropout
         |
   [Hidden 2]    ‚óã ‚óã ‚óã ... (128 neurones)
         |
         | ‚Üê ICI : Linear ‚Üí BatchNorm ‚Üí ReLU ‚Üí Dropout
         |
   [Hidden 3]    ‚óã ‚óã ‚óã ... (64 neurones)
         |
         | ‚Üê ICI : Linear (pas d'activation)
         |
   [Output]      ‚óã ‚óã ‚óã ‚óã ‚óã (5 neurones = 5 actions)

Les neurones (‚óã) ne font que recevoir et envoyer des valeurs.
Tout le travail se passe dans les connexions (|) entre les couches !


Qu'est-ce que fait chaque op√©ration ?

1. Linear(23, 256) :
   - Prend 23 valeurs en entr√©e
   - Fait des calculs : y = W @ x + b (multiplication matricielle)
   - Produit 256 valeurs en sortie
   - Chaque valeur = combinaison pond√©r√©e des 23 entr√©es

   IMPORTANT : W est une MATRICE (256, 23) !
   - Chaque neurone de sortie (256 au total) a besoin de 23 poids
   - Total : 256 √ó 23 = 5,888 poids dans la matrice W

   Exemple visuel :
   W = ‚îå                     ‚îê
       ‚îÇ w‚ÇÅ,‚ÇÅ  w‚ÇÅ,‚ÇÇ  ... w‚ÇÅ,‚ÇÇ‚ÇÉ ‚îÇ  ‚Üê 23 poids du neurone 1
       ‚îÇ w‚ÇÇ,‚ÇÅ  w‚ÇÇ,‚ÇÇ  ... w‚ÇÇ,‚ÇÇ‚ÇÉ ‚îÇ  ‚Üê 23 poids du neurone 2
       ‚îÇ  ...   ...  ...  ...  ‚îÇ
       ‚îÇ w‚ÇÇ‚ÇÖ‚ÇÜ,‚ÇÅ ...  w‚ÇÇ‚ÇÖ‚ÇÜ,‚ÇÇ‚ÇÉ   ‚îÇ  ‚Üê 23 poids du neurone 256
       ‚îî                       ‚îò

   Pourquoi une matrice ?
   Dans un r√©seau fully-connected, CHAQUE neurone de sortie
   est connect√© √† TOUS les neurones d'entr√©e.
   ‚Üí Il faut un poids par connexion
   ‚Üí 256 neurones √ó 23 connexions = matrice (256, 23)

2. BatchNorm1d(256) :
   - Normalise les 256 valeurs
   - Centre autour de 0, variance ~1
   - Stabilise l'entra√Ænement

3. ReLU() :
   - Applique max(0, x) sur chaque valeur
   - Les valeurs n√©gatives deviennent 0
   - Les valeurs positives restent inchang√©es
   - Casse la lin√©arit√© (permet d'apprendre des fonctions complexes)

4. Dropout(0.3) :
   - Pendant l'entra√Ænement : met 30% des valeurs √† 0 al√©atoirement
   - Pendant l'√©valuation : ne fait rien
   - √âvite l'overfitting (emp√™che le r√©seau de m√©moriser)


Pourquoi on appelle √ßa "Linear" si on a ReLU (non-lin√©aire) ?

Parce que chaque couche Linear fait une transformation lin√©aire : y = W @ x + b
Mais le r√©seau COMPLET n'est pas lin√©aire gr√¢ce aux ReLU !

Sans ReLU : empiler des couches lin√©aires est inutile
   Linear(Linear(x)) = Linear(x)  ‚Üê √âquivalent √† une seule couche !

Avec ReLU : on peut apprendre des fonctions complexes
   Linear(ReLU(Linear(x))) ‚â† Linear(x)  ‚Üê Vraiment diff√©rent !


√âTAPE 9 : Un neurone, c'est quoi exactement ?
---------------------------------------------

IMPORTANT : UN NEURONE = UN SEUL NOMBRE (pas un vecteur)

Exemple avec Linear(23, 256) :
- On a 23 valeurs en entr√©e : [0.5, -0.2, 0.8, ..., 1.0]
- On cr√©e 256 neurones diff√©rents
- Chaque neurone calcule SA PROPRE somme pond√©r√©e :

   Neurone 1: w‚ÇÅ‚ÇÅ√ó0.5 + w‚ÇÅ‚ÇÇ√ó(-0.2) + ... + b‚ÇÅ = 2.3   ‚Üê UN nombre
   Neurone 2: w‚ÇÇ‚ÇÅ√ó0.5 + w‚ÇÇ‚ÇÇ√ó(-0.2) + ... + b‚ÇÇ = -0.7  ‚Üê UN nombre
   Neurone 3: w‚ÇÉ‚ÇÅ√ó0.5 + w‚ÇÉ‚ÇÇ√ó(-0.2) + ... + b‚ÇÉ = 1.5   ‚Üê UN nombre
   ...
   Neurone 256: w‚ÇÇ‚ÇÖ‚ÇÜ√ó0.5 + ... + b‚ÇÇ‚ÇÖ‚ÇÜ = 0.9           ‚Üê UN nombre

Output : [2.3, -0.7, 1.5, ..., 0.9]  (256 nombres)

Ensuite ces 256 nombres passent par BatchNorm, ReLU, Dropout :

   Apr√®s Linear:    [2.3, -0.7, 1.5, ..., 0.9]
   Apr√®s BatchNorm: [1.1, -0.3, 0.8, ..., 0.5]  (normalis√©s)
   Apr√®s ReLU:      [1.1,  0.0, 0.8, ..., 0.5]  (-0.3 ‚Üí 0)
   Apr√®s Dropout:   [1.1,  0.0, 0.0, ..., 0.5]  (30% mis √† 0)


√âTAPE 10 : Pourquoi W est une MATRICE (et pas juste des nombres) ?
------------------------------------------------------------------

Dans un r√©seau fully-connected (MLP), CHAQUE neurone de sortie est connect√©
√† TOUS les neurones d'entr√©e. Il faut donc un poids pour CHAQUE connexion !

Exemple simple : 3 inputs ‚Üí 2 outputs

   Input (3)              Output (2)
     x‚ÇÅ ‚îÄ‚îÄ‚îÄw‚ÇÅ‚ÇÅ‚îÄ‚îÄ‚Üí ‚îê
     x‚ÇÇ ‚îÄ‚îÄ‚îÄw‚ÇÅ‚ÇÇ‚îÄ‚îÄ‚Üí ‚îú‚îÄ‚îÄ‚Üí y‚ÇÅ = w‚ÇÅ‚ÇÅ√óx‚ÇÅ + w‚ÇÅ‚ÇÇ√óx‚ÇÇ + w‚ÇÅ‚ÇÉ√óx‚ÇÉ + b‚ÇÅ
     x‚ÇÉ ‚îÄ‚îÄ‚îÄw‚ÇÅ‚ÇÉ‚îÄ‚îÄ‚Üí ‚îò

     x‚ÇÅ ‚îÄ‚îÄ‚îÄw‚ÇÇ‚ÇÅ‚îÄ‚îÄ‚Üí ‚îê
     x‚ÇÇ ‚îÄ‚îÄ‚îÄw‚ÇÇ‚ÇÇ‚îÄ‚îÄ‚Üí ‚îú‚îÄ‚îÄ‚Üí y‚ÇÇ = w‚ÇÇ‚ÇÅ√óx‚ÇÅ + w‚ÇÇ‚ÇÇ√óx‚ÇÇ + w‚ÇÇ‚ÇÉ√óx‚ÇÉ + b‚ÇÇ
     x‚ÇÉ ‚îÄ‚îÄ‚îÄw‚ÇÇ‚ÇÉ‚îÄ‚îÄ‚Üí ‚îò

On a besoin de 6 poids (2√ó3) !
Ces 6 poids forment une matrice W de taille (2, 3) :

   W = [ w‚ÇÅ‚ÇÅ  w‚ÇÅ‚ÇÇ  w‚ÇÅ‚ÇÉ ]   ‚Üê poids pour calculer y‚ÇÅ
       [ w‚ÇÇ‚ÇÅ  w‚ÇÇ‚ÇÇ  w‚ÇÇ‚ÇÉ ]   ‚Üê poids pour calculer y‚ÇÇ

En notation matricielle : y = W @ x + b

Dans notre r√©seau Pacman :
- Linear(23, 256)  ‚Üí W‚ÇÅ : matrice 256√ó23 = 5,888 poids !
- Linear(256, 128) ‚Üí W‚ÇÇ : matrice 128√ó256 = 32,768 poids !
- Linear(128, 64)  ‚Üí W‚ÇÉ : matrice 64√ó128 = 8,192 poids !
- Linear(64, 5)    ‚Üí W‚ÇÑ : matrice 5√ó64 = 320 poids !

TOTAL : 47,168 poids dans le r√©seau !


√âTAPE 11 : Entra√Ænement vs √âvaluation
-------------------------------------

ENTRA√éNEMENT (model.train()) :
- On modifie les poids pour apprendre
- Dropout activ√© : d√©sactive 30% des neurones al√©atoirement
- On calcule la loss et les gradients
- On fait backward() et step()

√âVALUATION (model.eval()) :
- On teste le r√©seau sans modifier les poids
- Dropout d√©sactiv√© : utilise TOUS les neurones
- On calcule juste l'accuracy
- PAS de backward(), PAS de step()


√âTAPE 12 : Analogie finale pour tout comprendre
-----------------------------------------------

Imagine que tu apprends √† tirer au basket :

- Forward pass = tu tires au panier
- Loss = distance entre le ballon et le panier (ton erreur)
- Gradients = "j'aurais d√ª tirer plus fort" ou "plus √† gauche"
- Optimizer = tu ajustes ta technique pour le prochain tir
- Epochs = tu t'entra√Ænes pendant des semaines

Au d√©but tu rates beaucoup (loss √©lev√©e).
Apr√®s 150 jours d'entra√Ænement, tu r√©ussis 87% de tes tirs (accuracy = 87%).

C'est exactement pareil pour le r√©seau de neurones !


================================================================================
PARTIE 1 : Vue d'ensemble du projet
================================================================================

BUT DU PROJET
-------------
Apprendre √† Pacman √† imiter un expert en utilisant l'apprentissage supervis√©.

On a :
- Un dataset de 15,018 exemples : (√©tat du jeu, action de l'expert)
- Un expert qui joue tr√®s bien √† Pacman

On veut :
- Entra√Æner un r√©seau de neurones √† pr√©dire quelle action l'expert aurait prise


LES 5 FICHIERS PRINCIPAUX
-------------------------

1. data.py
   ‚Üí Transforme l'√©tat du jeu en 23 nombres
   ‚Üí Le r√©seau ne comprend que les nombres, pas les objets Python

2. architecture.py
   ‚Üí D√©finit le cerveau du r√©seau : 23 ‚Üí 256 ‚Üí 128 ‚Üí 64 ‚Üí 5
   ‚Üí 3 couches cach√©es avec ReLU et Dropout

3. train.py
   ‚Üí Entra√Æne le r√©seau sur 150 epochs
   ‚Üí Sauvegarde le meilleur mod√®le

4. pacmanagent.py
   ‚Üí Utilise le mod√®le entra√Æn√© pour jouer

5. write_submission.py
   ‚Üí G√©n√®re le fichier CSV avec les pr√©dictions pour Gradescope


STRUCTURE DES DONN√âES
---------------------

Entra√Ænement :
- 15,018 exemples au total
- Split 80/20 : 12,014 pour l'entra√Ænement, 3,004 pour le test
- Batch size 256 : on traite 256 exemples √† la fois
- 47 batches par epoch

Test :
- Fichier s√©par√© : pacman_test.pkl (pour Gradescope)
- Contient SEULEMENT des √©tats de jeu (pas d'actions)
- On doit pr√©dire l'action pour chaque √©tat


================================================================================
PARTIE 2 : Les fichiers du projet
================================================================================

Structure du projet :

project2/
‚îú‚îÄ‚îÄ datasets/
‚îÇ   ‚îú‚îÄ‚îÄ pacman_dataset.pkl    ‚Üí Donn√©es d'entra√Ænement (15,018 exemples)
‚îÇ   ‚îî‚îÄ‚îÄ pacman_test.pkl       ‚Üí Donn√©es de test (pour Gradescope)
‚îÇ
‚îú‚îÄ‚îÄ pacman_module/            ‚Üí Moteur de jeu (NE PAS MODIFIER)
‚îÇ   ‚îú‚îÄ‚îÄ game.py
‚îÇ   ‚îú‚îÄ‚îÄ pacman.py
‚îÇ   ‚îú‚îÄ‚îÄ layout.py
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ
‚îú‚îÄ‚îÄ data.py                   ‚Üí Transforme GameState en 23 features
‚îú‚îÄ‚îÄ architecture.py           ‚Üí D√©finit le r√©seau MLP
‚îú‚îÄ‚îÄ train.py                  ‚Üí Entra√Æne le mod√®le
‚îú‚îÄ‚îÄ pacmanagent.py            ‚Üí Agent qui utilise le mod√®le
‚îú‚îÄ‚îÄ run.py                    ‚Üí Visualise le jeu
‚îú‚îÄ‚îÄ write_submission.py       ‚Üí G√©n√®re le CSV pour Gradescope
‚îÇ
‚îú‚îÄ‚îÄ pacman_model.pth          ‚Üí Poids du mod√®le entra√Æn√©
‚îî‚îÄ‚îÄ submission.csv            ‚Üí Pr√©dictions pour Gradescope


================================================================================
PARTIE 3 : data.py - Transformer l'√©tat du jeu en nombres
================================================================================

PROBL√àME
--------
Un r√©seau de neurones ne peut pas comprendre directement un GameState.
Il faut transformer l'√©tat du jeu en nombres.


LES 23 FEATURES
---------------

Notre r√©seau prend 23 nombres en entr√©e. Voici ce qu'ils repr√©sentent :


1. POSITION DE PACMAN (2 features)
   [0] pac_x / maze_width    ‚Üí Position X normalis√©e
   [1] pac_y / maze_height   ‚Üí Position Y normalis√©e


2. INFORMATION SUR LE FANT√îME (4 features)
   [2] (ghost_x - pac_x) / maze_width   ‚Üí Direction X vers le fant√¥me
   [3] (ghost_y - pac_y) / maze_height  ‚Üí Direction Y vers le fant√¥me
   [4] distance_manhattan / max_dist    ‚Üí Distance au fant√¥me
   [5] ghost_adjacent                   ‚Üí 1 si fant√¥me √† c√¥t√©, 0 sinon


3. INFORMATION SUR LA NOURRITURE (4 features)
   [6] n_food / 50                      ‚Üí Nombre de pastilles restantes
   [7] (food_x - pac_x) / maze_width    ‚Üí Direction X vers la nourriture
   [8] (food_y - pac_y) / maze_height   ‚Üí Direction Y vers la nourriture
   [9] distance_food / max_dist         ‚Üí Distance √† la nourriture


4. G√âOM√âTRIE DU LABYRINTHE (5 features)
   [10] distance_nord / maze_height     ‚Üí Cases libres vers le nord
   [11] distance_sud / maze_height      ‚Üí Cases libres vers le sud
   [12] distance_est / maze_width       ‚Üí Cases libres vers l'est
   [13] distance_ouest / maze_width     ‚Üí Cases libres vers l'ouest
   [14] is_corner                       ‚Üí 1 si coin (‚â§2 directions), 0 sinon


5. NIVEAU DE DANGER (3 features)
   [15] danger_level                    ‚Üí 1 / max(dist_ghost, 0.5)
   [16] ghost_blocks_food               ‚Üí 1 si fant√¥me entre Pacman et food
   [17] escape_options                  ‚Üí Nombre de directions / 4


6. ACTIONS L√âGALES (5 features)
   [18] legal_north   ‚Üí 1 si on peut aller au nord, 0 sinon
   [19] legal_south   ‚Üí 1 si on peut aller au sud, 0 sinon
   [20] legal_east    ‚Üí 1 si on peut aller √† l'est, 0 sinon
   [21] legal_west    ‚Üí 1 si on peut aller √† l'ouest, 0 sinon
   [22] legal_stop    ‚Üí 1 si on peut s'arr√™ter, 0 sinon


POURQUOI NORMALISER ?
--------------------

Sans normalisation :
- Position X : entre 0 et 20
- Position Y : entre 0 et 20
- Distance : entre 0 et 40
- Legal flags : 0 ou 1

Probl√®me : les grandes valeurs (positions, distances) dominent les petites (flags).
Le r√©seau apprend mal.

Avec normalisation :
- Tout est entre 0 et 1
- Toutes les features ont la m√™me importance
- Le r√©seau apprend beaucoup mieux !


COMMENT ON TROUVE LA NOURRITURE LA PLUS PROCHE ?
------------------------------------------------

1. On r√©cup√®re toutes les positions de nourriture
   food_positions = [(5, 3), (7, 8), (2, 4), ...]

2. On calcule la distance Manhattan √† CHAQUE nourriture
   distance = |pac_x - food_x| + |pac_y - food_y|

3. On trouve laquelle est la plus proche
   min_distance = min(distances)

4. On calcule la direction vers cette nourriture
   direction_x = food_x - pac_x
   direction_y = food_y - pac_y


COMMENT ON CALCULE LA DISTANCE JUSQU'AU MUR ?
---------------------------------------------

La fonction dist_until_wall(x, y, dx, dy) compte combien de cases on peut
avancer dans une direction avant de toucher un mur.

Exemple visuel :

   # # # # # # #
   # . . . . . #
   # # P . . . #  ‚Üê Pacman en (2, 2)
   # # # . . . #
   # # # # # # #

   dist_until_wall(2, 2,  1, 0) = 3  (3 cases libres vers l'est)
   dist_until_wall(2, 2, -1, 0) = 0  (mur imm√©diat √† l'ouest)
   dist_until_wall(2, 2,  0, 1) = 1  (1 case libre vers le nord)


CONVERSION DES ACTIONS EN INDICES
---------------------------------

Le r√©seau ne comprend pas les objets Python comme Directions.NORTH.
On doit convertir en indices (nombres) :

ACTION_TO_INDEX = {
   Directions.NORTH: 0,
   Directions.SOUTH: 1,
   Directions.EAST: 2,
   Directions.WEST: 3,
   Directions.STOP: 4
}

INDEX_TO_ACTION = {0: NORTH, 1: SOUTH, 2: EAST, 3: WEST, 4: STOP}

Pendant l'entra√Ænement :
   Expert joue EAST ‚Üí converti en indice 2 ‚Üí Le r√©seau apprend √† pr√©dire 2

Pendant l'inf√©rence :
   R√©seau pr√©dit [0.05, 0.1, 0.75, 0.08, 0.02]
   ‚Üí argmax = 2
   ‚Üí reconverti en EAST


================================================================================
PARTIE 4 : architecture.py - Le cerveau du r√©seau
================================================================================

CHOIX D'ARCHITECTURE : POURQUOI UN MLP ?
----------------------------------------

MLP = Multi-Layer Perceptron = r√©seau de neurones fully-connected

On n'utilise PAS de CNN (Convolutional Neural Network) parce que :
- Les CNN sont faits pour les images 2D (pixels voisins sont li√©s)
- Notre input est un vecteur 1D de 23 nombres
- Pas de relation spatiale entre les features
- Un MLP simple est le bon choix


STRUCTURE DU R√âSEAU
-------------------

23 inputs ‚Üí 256 ‚Üí 128 ‚Üí 64 ‚Üí 5 outputs

Input Layer:     23 neurones (nos 23 features)
Hidden Layer 1:  256 neurones
Hidden Layer 2:  128 neurones
Hidden Layer 3:  64 neurones
Output Layer:    5 neurones (les 5 actions)

Total : 47,168 poids √† apprendre !


PATTERN DE CHAQUE COUCHE CACH√âE
-------------------------------

Pour chaque couche cach√©e, on applique 4 op√©rations dans l'ordre :

1. Linear(in, out)
   ‚Üí Transformation lin√©aire : y = W @ x + b
   ‚Üí Calcule les combinaisons pond√©r√©es

2. BatchNorm1d(out)
   ‚Üí Normalise les valeurs (moyenne=0, variance=1)
   ‚Üí Stabilise l'entra√Ænement

3. ReLU()
   ‚Üí Fonction d'activation : f(x) = max(0, x)
   ‚Üí Met les valeurs n√©gatives √† 0
   ‚Üí Casse la lin√©arit√© (permet d'apprendre des fonctions complexes)

4. Dropout(0.3)
   ‚Üí √âteint al√©atoirement 30% des neurones pendant l'entra√Ænement
   ‚Üí √âvite l'overfitting (emp√™che le r√©seau de m√©moriser)


POURQUOI ReLU ?
--------------

ReLU est l'activation standard pour les MLPs :
- Simple : f(x) = max(0, x)
- Rapide √† calculer
- R√©sout le probl√®me du vanishing gradient
- Permet une convergence rapide

Alternative : GELU (plus smooth), mais ReLU fonctionne tr√®s bien ici.


POURQUOI BATCHNORM ?
-------------------

Sans BatchNorm, l'entra√Ænement √©tait instable.
BatchNorm normalise les valeurs entre les couches.

Avantages :
- Stabilise les gradients
- Permet d'utiliser un learning rate plus √©lev√©
- Convergence plus rapide


POURQUOI DROPOUT ?
-----------------

Dropout = r√©gularisation pour √©viter l'overfitting

Dropout(0.3) signifie :
- Pendant l'entra√Ænement : √©teint 30% des neurones al√©atoirement
- Pendant l'√©valuation : utilise TOUS les neurones

Pourquoi √ßa marche ?
- Force le r√©seau √† ne pas trop d√©pendre de certains neurones
- Le r√©seau apprend des patterns plus robustes
- G√©n√©ralise mieux sur de nouveaux exemples

Valeur optimale : 0.3 (test√© empiriquement)
- Trop de dropout (0.5) : underfitting
- Pas assez (0.1) : overfitting


PAS D'ACTIVATION SUR LA DERNI√àRE COUCHE
---------------------------------------

La derni√®re couche est juste Linear(64, 5), sans ReLU.

Pourquoi ?
- On veut des valeurs brutes (logits) : [-2.1, 0.5, 3.2, 1.0, -0.3]
- CrossEntropyLoss fait le Softmax automatiquement
- Pas besoin de mettre Softmax dans le r√©seau


CODE SIMPLIFI√â
--------------

def __init__(self):
    layers = []

    # Couche 1 : 23 ‚Üí 256
    layers.append(nn.Linear(23, 256))
    layers.append(nn.BatchNorm1d(256))
    layers.append(nn.ReLU())
    layers.append(nn.Dropout(0.3))

    # Couche 2 : 256 ‚Üí 128
    layers.append(nn.Linear(256, 128))
    layers.append(nn.BatchNorm1d(128))
    layers.append(nn.ReLU())
    layers.append(nn.Dropout(0.3))

    # Couche 3 : 128 ‚Üí 64
    layers.append(nn.Linear(128, 64))
    layers.append(nn.BatchNorm1d(64))
    layers.append(nn.ReLU())
    layers.append(nn.Dropout(0.3))

    # Couche de sortie : 64 ‚Üí 5
    layers.append(nn.Linear(64, 5))

    self.net = nn.Sequential(*layers)
    self.criterion = nn.CrossEntropyLoss()


================================================================================
PARTIE 5 : train.py - Apprendre au r√©seau
================================================================================

PIPELINE D'ENTRA√éNEMENT
-----------------------

1. Charger le dataset (15,018 exemples)
2. Split train/test 80/20 (12,014 train / 3,004 test)
3. Cr√©er les DataLoaders avec batch_size=256
4. Entra√Æner pendant 150 epochs
5. √âvaluer sur le test set √† chaque epoch
6. Sauvegarder le meilleur mod√®le


HYPERPARAM√àTRES
--------------

batch_size = 256
- Traite 256 exemples √† la fois
- Gradients plus stables (moyenne sur 256 exemples)
- Plus efficace pour le GPU

epochs = 150
- R√©p√®te l'entra√Ænement 150 fois sur tout le dataset
- Suffisant pour converger compl√®tement
- Le meilleur mod√®le est g√©n√©ralement vers epoch 120-130

learning_rate = 8e-4 (0.0008)
- L√©g√®rement √©lev√© pour converger plus vite
- Pas trop √©lev√© pour rester stable

test_ratio = 0.2
- 20% des donn√©es pour tester
- 80% pour entra√Æner


LA LOSS FUNCTION : CROSSENTROPYLOSS
-----------------------------------

CrossEntropyLoss est LA loss standard pour la classification multi-classe.

Comment √ßa marche ?

√âTAPE 1 : Le r√©seau produit des logits
   [2.1, 0.5, 3.2, 1.0, 0.3]

√âTAPE 2 : Softmax transforme en probabilit√©s
   [0.18, 0.04, 0.54, 0.06, 0.03]
   (somme = 1.0)

√âTAPE 3 : On prend le log des probabilit√©s
   [log(0.18), log(0.04), log(0.54), log(0.06), log(0.03)]

√âTAPE 4 : On s√©lectionne la bonne action et on calcule -log(proba)
   Si la bonne action est NORTH (indice 0) :
   Loss = -log(0.18) = 1.71

√âTAPE 5 : On fait la moyenne sur tout le batch
   Loss_batch = moyenne de toutes les losses

PyTorch fait TOUT √ßa automatiquement avec CrossEntropyLoss() !


L'OPTIMIZER : ADAM
-----------------

Adam (Adaptive Moment Estimation) est l'optimizer standard en deep learning.

Pourquoi Adam ?
- Adapte le learning rate pour chaque poids individuellement
- Converge plus vite que Gradient Descent classique
- Plus stable (moins de variations)

Comment √ßa marche ?
1. Calcule la moyenne des gradients r√©cents (momentum)
2. Calcule la variance des gradients r√©cents
3. Ajuste le learning rate selon ces statistiques

R√©sultat :
- GRANDS pas quand le gradient est stable et fort (on est loin du minimum)
- PETITS pas quand le gradient est instable ou faible (on est proche du minimum)


BOUCLE D'ENTRA√éNEMENT COMPL√àTE
------------------------------

```python
for epoch in range(150):
    model.train()  # Mode entra√Ænement (dropout activ√©)

    for features, actions in train_loader:
        # 1. Forward pass
        loss = model.loss(features, actions)

        # 2. Backward pass
        optim.zero_grad()  # Efface les anciens gradients
        loss.backward()    # Calcule les nouveaux gradients
        optim.step()       # Met √† jour les poids

    # √âvaluation sur le test set
    model.eval()  # Mode √©valuation (dropout d√©sactiv√©)
    accuracy = evaluate(model, test_loader)

    # Sauvegarde du meilleur mod√®le
    if accuracy > best_accuracy:
        best_accuracy = accuracy
        torch.save(model.state_dict(), 'pacman_model.pth')

    print(f"Epoch {epoch}: Accuracy = {accuracy:.2f}%")
```


CHECKPOINTING : SAUVEGARDER LE MEILLEUR MOD√àLE
----------------------------------------------

√Ä chaque epoch, on √©value l'accuracy sur le test set.
Si c'est la meilleure accuracy jusqu'√† maintenant, on sauvegarde le mod√®le.

Pourquoi ?
- Le dernier mod√®le (epoch 150) n'est pas toujours le meilleur
- Il peut avoir overfitt√© (m√©moris√© les donn√©es d'entra√Ænement)
- Le meilleur mod√®le est celui qui g√©n√©ralise le mieux (meilleure test accuracy)

Le mod√®le est sauvegard√© dans pacman_model.pth


R√âSULTATS TYPIQUES
-----------------

Epoch 1:   Accuracy ‚âà 60%  (commence al√©atoire)
Epoch 50:  Accuracy ‚âà 82%
Epoch 100: Accuracy ‚âà 86%
Epoch 120: Accuracy ‚âà 87.5%  ‚Üê Meilleur mod√®le
Epoch 150: Accuracy ‚âà 87.2%  (l√©g√®re baisse = overfitting)

Pourquoi l'accuracy plafonne √† ~87-88% ?
- Dans certaines situations, plusieurs actions sont √©galement bonnes
- Le r√©seau peut choisir une action diff√©rente de l'expert, mais tout aussi valide
- C'est normal et ne veut pas dire que le mod√®le est mauvais


================================================================================
PARTIE 6 : write_submission.py - G√©n√©rer les pr√©dictions
================================================================================

OBJECTIF
--------
G√©n√©rer un fichier submission.csv avec les pr√©dictions pour Gradescope.


DIFF√âRENCE ENTRE TRAIN SET ET TEST SET
--------------------------------------

Train set (pacman_dataset.pkl) :
- Contient : (GameState, action) paires
- 15,018 exemples
- On conna√Æt l'action de l'expert
- Utilis√© pour entra√Æner le r√©seau

Test set (pacman_test.pkl) :
- Contient : SEULEMENT des GameState (pas d'actions !)
- Nombre d'exemples inconnu
- On doit PR√âDIRE l'action
- Utilis√© pour Gradescope


√âTAPE 1 : INITIALISATION
------------------------

```python
def __init__(self, test_set_path, model_path):
    # Charger le test set
    with open(test_set_path, 'rb') as f:
        self.test_set = pickle.load(f)

    # Charger le mod√®le
    self.model = PacmanNetwork()
    self.model.load_state_dict(torch.load(model_path))

    # Mode √©valuation (dropout d√©sactiv√©)
    self.model.eval()
```


√âTAPE 2 : PR√âDICTION
--------------------

Pour chaque √©tat du test set, on fait une pr√©diction :

```python
def predict_on_testset(self):
    actions = []

    for state in self.test_set:
        # 1. Convertir GameState en tensor (23 features)
        x = state_to_tensor(state)

        # 2. Ajouter dimension batch (1, 23)
        x = x.unsqueeze(0)

        # 3. D√©sactiver les gradients (on ne fait que de l'inf√©rence)
        with torch.no_grad():
            # 4. Forward pass
            logits = self.model(x)

            # 5. Prendre l'action avec le score le plus √©lev√©
            pred_index = logits.argmax(dim=1).item()

            # 6. Convertir l'indice en action
            action = INDEX_TO_ACTION[pred_index]

            # 7. Ajouter √† la liste
            actions.append(action)

    return actions
```


√âTAPE 3 : √âCRITURE DU CSV
-------------------------

```python
def write_csv(self, actions, file_name="submission"):
    # Cr√©er un DataFrame pandas
    df = pd.DataFrame({'ACTION': actions})

    # √âcrire dans submission.csv
    df.to_csv(file_name + '.csv', index=False)
```

Format du CSV :
```
ACTION
North
East
East
West
South
...
```


POINTS IMPORTANTS
----------------

1. torch.no_grad()
   - D√©sactive le calcul des gradients
   - √âconomise de la m√©moire
   - Acc√©l√®re l'inf√©rence

2. model.eval()
   - D√©sactive le dropout
   - Utilise TOUS les neurones
   - Pr√©dictions d√©terministes (toujours les m√™mes pour un √©tat donn√©)

3. unsqueeze(0)
   - Ajoute une dimension batch
   - (23,) devient (1, 23)
   - Le mod√®le attend toujours un batch (m√™me d'un seul exemple)

4. argmax(dim=1)
   - Prend l'indice du maximum
   - [2.1, 0.5, 3.2, 1.0, 0.3] ‚Üí indice 2 (EAST)

5. ORDRE IMPORTANT
   - Les pr√©dictions doivent √™tre dans le M√äME ORDRE que le test set
   - On ne peut pas trier ou m√©langer les pr√©dictions


UTILISATION
----------

```python
# Cr√©er le writer
writer = SubmissionWriter(
    test_set_path="datasets/pacman_test.pkl",
    model_path="pacman_model.pth"
)

# G√©n√©rer les pr√©dictions
predictions = writer.predict_on_testset()

# √âcrire le CSV
writer.write_csv(predictions)
```

R√©sultat : fichier submission.csv cr√©√© avec toutes les pr√©dictions.


================================================================================
PARTIE 7 : Questions fr√©quentes (FAQ)
================================================================================

Q: Pourquoi un MLP et pas un CNN ?
-----------------------------------
R: Les CNN sont faits pour les images 2D o√π les pixels voisins sont li√©s.
   Notre input est un vecteur 1D de 23 nombres sans relation spatiale.
   Un MLP est le bon choix pour ce type de donn√©es.


Q: Pourquoi normaliser les features ?
--------------------------------------
R: Les r√©seaux de neurones convergent mieux quand toutes les features
   sont dans la m√™me √©chelle (~[0, 1]).
   Sans normalisation :
   - Position X : 0-20
   - Distance : 0-40
   - Legal flags : 0-1
   Les grandes valeurs domineraient les petites.
   Avec normalisation, tout est ~[0, 1] et le r√©seau apprend bien mieux.


Q: Pourquoi ReLU au lieu de GELU ?
-----------------------------------
R: ReLU est plus simple et rapide : f(x) = max(0, x)
   GELU est plus smooth (gradients plus fluides), mais ReLU fonctionne
   tr√®s bien pour ce probl√®me et converge rapidement.
   ReLU est l'activation standard dans les MLPs classiques.


Q: Pourquoi BatchNorm ?
------------------------
R: Sans BatchNorm, l'entra√Ænement √©tait instable.
   BatchNorm normalise les valeurs entre couches pour stabiliser les gradients.
   Permet d'utiliser un learning rate plus √©lev√© et convergence plus rapide.


Q: Pourquoi CrossEntropyLoss ?
-------------------------------
R: C'est LA loss standard pour la classification multi-classe.
   Elle combine Softmax + Log + S√©lection + Moyenne en une seule op√©ration.
   Num√©riquement stable et efficace.


Q: Pourquoi 150 epochs ?
-------------------------
R: Optimis√© empiriquement.
   - 50 epochs : pas assez, accuracy ~82%
   - 100 epochs : bien, accuracy ~86%
   - 150 epochs : optimal, accuracy ~87-88%
   - 200 epochs : overfitting, accuracy baisse
   Le meilleur mod√®le est g√©n√©ralement vers epoch 120-130.


Q: Pourquoi dropout = 0.3 ?
----------------------------
R: Balance entre r√©gularisation et capacit√© du r√©seau.
   - dropout = 0.1 : risque d'overfitting
   - dropout = 0.3 : optimal (sweet spot)
   - dropout = 0.5 : underfitting
   Test√© empiriquement.


Q: Pourquoi batch_size = 256 ?
-------------------------------
R: - Gradients plus stables (moyenne sur 256 exemples)
   - Plus efficace pour le GPU
   - Bon compromis entre vitesse et stabilit√©
   - Batch size plus petit (32) : gradients instables
   - Batch size plus grand (512) : moins de mises √† jour par epoch


Q: Comment g√©rer les actions ill√©gales ?
-----------------------------------------
R: Dans pacmanagent.py, on trie les pr√©dictions par probabilit√©
   et on prend la premi√®re action qui est dans la liste des actions l√©gales.
   Le r√©seau apprend √† √©viter les actions ill√©gales car il a les
   legal_flags dans ses features d'entr√©e.


Q: Pourquoi l'accuracy plafonne √† ~87-88% ?
--------------------------------------------
R: Dans ~10-15% des situations, plusieurs actions sont √©galement bonnes.
   Exemple : fant√¥me loin, plusieurs chemins vers la nourriture.
   Le r√©seau peut choisir une action diff√©rente de l'expert, mais tout
   aussi valide. L'accuracy mesure seulement si c'est EXACTEMENT la m√™me
   action que l'expert, pas si c'est une bonne action.


Q: Est-ce que le mod√®le fonctionne sur diff√©rents labyrinthes ?
----------------------------------------------------------------
R: Oui ! Les features sont adaptatives :
   - Positions normalis√©es par maze_width et maze_height
   - Distances normalis√©es par la taille du labyrinthe
   - legal_actions s'adapte automatiquement aux murs
   - dist_until_wall d√©tecte les murs dans chaque direction

   Le mod√®le a appris des patterns g√©n√©raux (fuir les fant√¥mes, aller
   vers la nourriture, √©viter les coins) pas juste √† m√©moriser un labyrinthe.


Q: Comment convertir les actions en indices ?
----------------------------------------------
R: Le r√©seau ne comprend que les nombres, pas les objets Python.
   On cr√©e deux mappings :

   ACTION_TO_INDEX = {
      Directions.NORTH: 0,
      Directions.SOUTH: 1,
      Directions.EAST: 2,
      Directions.WEST: 3,
      Directions.STOP: 4
   }

   INDEX_TO_ACTION = {0: NORTH, 1: SOUTH, 2: EAST, 3: WEST, 4: STOP}

   Entra√Ænement : Expert joue EAST ‚Üí indice 2 ‚Üí R√©seau apprend √† pr√©dire 2
   Inf√©rence : R√©seau pr√©dit 2 ‚Üí reconverti en EAST


Q: Quelle est la feature la plus importante ?
----------------------------------------------
R: Les features de danger sont les plus importantes :
   - danger_level : gradient de danger (1 / distance)
   - ghost_blocks_food : fant√¥me entre Pacman et la nourriture ?
   - escape_options : combien de directions pour fuir ?

   Sans ces features, le mod√®le avait du mal √† √©viter les fant√¥mes.
   Avec ces features, accuracy +5%.


Q: Pourquoi utiliser Adam au lieu de SGD ?
-------------------------------------------
R: Adam adapte automatiquement le learning rate pour chaque poids.
   - SGD : m√™me learning rate pour tous les poids
   - Adam : learning rate adaptatif et intelligent

   R√©sultat : converge plus vite et de mani√®re plus stable.
   C'est l'optimizer standard en deep learning.


================================================================================
FIN DE LA DOCUMENTATION
================================================================================

Pour plus d'informations, consulter :
- Le code source (bien comment√©)
- La documentation PyTorch : https://pytorch.org/docs/
- Le cours th√©orique sur les r√©seaux de neurones

Bon courage pour le projet ! üéÆ
