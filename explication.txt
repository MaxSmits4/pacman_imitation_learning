================================================================================
PROJECT 2 - PACMAN IMITATION LEARNING
Documentation complète et simplifiée
================================================================================


TABLE DES MATIÈRES
==================

PARTIE 0 : Comment fonctionne un réseau de neurones ? (pour bien comprendre)
PARTIE 1 : Vue d'ensemble du projet
PARTIE 2 : Les fichiers du projet
PARTIE 3 : data.py - Transformer l'état du jeu en nombres
PARTIE 4 : architecture.py - Le cerveau du réseau
PARTIE 5 : train.py - Apprendre au réseau
PARTIE 6 : write_submission.py - Générer les prédictions
PARTIE 7 : Questions fréquentes (FAQ)


================================================================================
PARTIE 0 : Comment fonctionne un réseau de neurones ?
================================================================================

Cette partie explique les bases pour bien comprendre le projet.


ÉTAPE 1 : C'est quoi un réseau de neurones ?
---------------------------------------------

Imagine une fonction mathématique magique : f(x) = y

- Tu donnes des informations en entrée (x)
- La fonction te donne une réponse en sortie (y)

Exemple pour Pacman :
- ENTRÉE (x) : Position de Pacman, position du fantôme, où est la nourriture
- SORTIE (y) : Quelle direction prendre ? (NORTH, SOUTH, EAST, WEST, STOP)

Cette fonction contient des milliers de nombres appelés "poids" (weights).
Au début, ces poids sont aléatoires → la fonction fait n'importe quoi.
Le but de l'entraînement : ajuster ces poids pour que la fonction donne les bonnes réponses.


ÉTAPE 2 : Comment le réseau fait une prédiction ? (Forward Pass)
-----------------------------------------------------------------

C'est le moment où on demande au réseau : "Que dois-je faire ?"

Exemple concret :
1. x: [0.25, 0.30, 0.8, ..., 1, 0]  (23 nombres)

2. Le réseau fait ses calculs :
   Input (23 nombres)
     ↓
   Linear → BatchNorm → GELU → Dropout
     ↓
   Linear → BatchNorm → GELU → Dropout
     ↓
   Linear → BatchNorm → GELU → Dropout
     ↓
   Linear (dernière couche)
     ↓
   Output : [2.1, 0.5, 3.2, 1.0, 0.3]

3. On regarde quel nombre est le plus grand :
   [2.1, 0.5, 3.2, 1.0, 0.3]
    ↑    ↑    ↑    ↑    ↑
   NORTH SOUTH EAST WEST STOP

   3.2 est le plus grand → Le réseau prédit EAST


ÉTAPE 3 : Comment mesurer si le réseau s'est trompé ? (Loss)
------------------------------------------------------------

Problème : Le réseau a prédit EAST, mais l'expert voulait NORTH !

La "loss" (perte) mesure l'erreur :
- Si le réseau a raison → loss = 0 (parfait !)
- Si le réseau se trompe → loss = grand nombre (mauvais !)

Comment on calcule la loss ?

1. On transforme les nombres en probabilités avec Softmax :
  y= [2.1, 0.5, 3.2, 1.0, 0.3]  →  [0.18, 0.04, 0.54, 0.06, 0.03]

   Maintenant les nombres font tous ensemble = 1.0 (100%)
   C'est comme dire : "Je suis sûr à 18% que c'est NORTH, 54% que c'est EAST..."

2. On regarde la probabilité de la bonne action (NORTH = 0.18 = 18%)

3. On calcule la loss :
   Loss = -log(0.18) = 1.71

Plus la probabilité est basse, plus la loss est grande.
Si la probabilité était 1.0 (100% sûr), la loss serait 0 (parfait).


ÉTAPE 4 : Comment corriger les erreurs ? (Backward Pass)
--------------------------------------------------------

Maintenant qu'on sait que le réseau s'est trompé (loss = 1.71),
on veut ajuster les poids pour réduire cette erreur.

Question : Dans quelle direction faut-il bouger chaque poids ?
Réponse : Les GRADIENTS nous le disent !

Un gradient, c'est comme une flèche qui dit :
- "Augmente ce poids" (gradient positif)
- "Diminue ce poids" (gradient négatif)
- "Ne touche pas ce poids" (gradient proche de zéro)

Exemple simple :
- Un poids w = 0.5
- Son gradient = -0.3
- Signification : Si j'augmente w, la loss diminue ! (c'est bien)

Le réseau contient 14,021 paramètres apprenables au total.
PyTorch calcule automatiquement le gradient de CHAQUE paramètre avec loss.backward().


ÉTAPE 5 : Comment ajuster les poids ? (Optimizer)
-------------------------------------------------

Maintenant qu'on a les gradients, on met à jour les poids.

IMPORTANT : Les gradients sont des MATRICES !
- La loss L = 1 nombre (scalaire)
- Les poids W = matrice (par exemple 128 × 23)
- Le gradient ∇W L = matrice de la MÊME TAILLE que W

Exemple pour Linear(23, 128) :
   W = matrice (128, 23) avec 2,944 poids
   ∇W = matrice (128, 23) avec 2,944 gradients

Chaque case du gradient indique :
   "Si j'augmente ce poids, est-ce que la loss augmente ou diminue ?"

   Gradient positif → augmenter ce poids fait AUGMENTER la loss
                   → donc on DIMINUE ce poids
   Gradient négatif → augmenter ce poids fait DIMINUER la loss
                   → donc on AUGMENTE ce poids

Formule de base (appliquée à CHAQUE poids) :
   nouveau_poids = ancien_poids - learning_rate × gradient

Exemple pour UN poids :
- Ancien poids : w = 0.5
- Gradient : -0.3
- Learning rate : 0.0008
- Nouveau poids : w = 0.5 - 0.0008 × (-0.3) = 0.50024

Mais on fait ça pour les 14,021 paramètres du réseau !

On utilise Adam (optimizer intelligent) :
- Il adapte automatiquement le learning_rate pour chaque poids
- Il fait de GRANDS pas quand il est sûr de la direction
- Il fait de PETITS pas quand il hésite
- Résultat : converge plus vite et de manière plus stable


ÉTAPE 6 : Le cycle complet d'entraînement
-----------------------------------------

Une itération d'entraînement, c'est ces 4 étapes :

```
for epoch in range(150):                       # Répéter 150 fois
    for features, actions in loader_train:     # Pour chaque batch

        1. loss = model.loss(features, actions)
           → Forward pass : calcule la prédiction et l'erreur cad loss

        2. optim.zero_grad()
           → Efface les anciens gradients

        3. loss.backward()
           → Backward pass : calcule les gradients

        4. optim.step()
           → Met à jour les poids avec les gradients
```

On répète ce cycle 7,050 fois (150 epochs × 47 batches).
À chaque fois, les poids s'améliorent un petit peu.


ÉTAPE 7 : Pourquoi des batches et des epochs ?
----------------------------------------------

Batch = groupe de 256 exemples traités ensemble
- Plus efficace pour le GPU
- Les gradients sont plus stables (moyenne sur 256 exemples)

Epoch = 1 passage complet sur tous les exemples (15,018 exemples)
- 1 epoch = 15,018 ÷ 256 = ~47 batches
- Le réseau a besoin de voir les exemples PLUSIEURS FOIS pour bien apprendre
- On fait 150 epochs pour que le réseau converge complètement


ÉTAPE 8 : Où se trouvent les opérations dans le réseau ?
--------------------------------------------------------

C'est une question importante pour bien comprendre !

Les opérations (Linear, BatchNorm, GELU, Dropout) ne sont PAS dans les neurones.
Elles se trouvent ENTRE les couches, dans les CONNEXIONS.

Visualisation :

   [Input Layer] ○ ○ ○ (23 neurones)
         |
         | ← ICI : Linear → BatchNorm → GELU → Dropout
         |
   [Hidden 1]    ○ ○ ○ ... (128 neurones)
         |
         | ← ICI : Linear → BatchNorm → GELU → Dropout
         |
   [Hidden 2]    ○ ○ ○ ... (64 neurones)
         |
         | ← ICI : Linear → BatchNorm → GELU → Dropout
         |
   [Hidden 3]    ○ ○ ○ ... (32 neurones)
         |
         | ← ICI : Linear (pas d'activation)
         |
   [Output]      ○ ○ ○ ○ ○ (5 neurones = 5 actions)

Les neurones (○) ne font que recevoir et envoyer des valeurs.
Tout le travail se passe dans les connexions (|) entre les couches !


Qu'est-ce que fait chaque opération ?

1. Linear(23, 128) :
   - Prend 23 valeurs en entrée
   - Fait des calculs : y = W @ x + b (multiplication matricielle)
   - Produit 128 valeurs en sortie
   - Chaque valeur = combinaison pondérée des 23 entrées

   IMPORTANT : W est une MATRICE (128, 23) !
   - Chaque neurone de sortie (128 au total) a besoin de 23 poids
   - Total : 128 × 23 = 2,944 poids dans la matrice W

   Exemple visuel :
   W = ┌                     ┐
       │ w₁,₁  w₁,₂  ... w₁,₂₃ │  ← 23 poids du neurone 1
       │ w₂,₁  w₂,₂  ... w₂,₂₃ │  ← 23 poids du neurone 2
       │  ...   ...  ...  ...  │
       │ w₁₂₈,₁ ...  w₁₂₈,₂₃   │  ← 23 poids du neurone 128
       └                       ┘

   Pourquoi une matrice ?
   Dans un réseau fully-connected, CHAQUE neurone de sortie
   est connecté à TOUS les neurones d'entrée.
   → Il faut un poids par connexion
   → 128 neurones × 23 connexions = matrice (128, 23)

2. BatchNorm1d(128) :
   - Normalise les 128 valeurs
   - Centre autour de 0, variance ~1
   - Stabilise l'entraînement

3. GELU() :
   - Applique une activation gaussienne lisse sur chaque valeur
   - Les valeurs négatives sont atténuées progressivement (pas coupées)
   - Les valeurs positives restent inchangées
   - Casse la linéarité (permet d'apprendre des fonctions complexes)

4. Dropout(0.3) :
   - Pendant l'entraînement : met 30% des valeurs à 0 aléatoirement
   - Pendant l'évaluation : ne fait rien
   - Évite l'overfitting (empêche le réseau de mémoriser)


Pourquoi on appelle ça "Linear" si on a GELU (non-linéaire) ?

Parce que chaque couche Linear fait une transformation linéaire : y = W @ x + b
Mais le réseau COMPLET n'est pas linéaire grâce aux GELU !

Sans GELU : empiler des couches linéaires est inutile
   Linear(Linear(x)) = Linear(x)  ← Équivalent à une seule couche !

Avec GELU : on peut apprendre des fonctions complexes
   Linear(GELU(Linear(x))) ≠ Linear(x)  ← Vraiment différent !


ÉTAPE 9 : Un neurone, c'est quoi exactement ?
---------------------------------------------

IMPORTANT : UN NEURONE = UN SEUL NOMBRE (pas un vecteur)

Exemple avec Linear(23, 128) :
- On a 23 valeurs en entrée : [0.5, -0.2, 0.8, ..., 1.0]
- On crée 128 neurones différents
- Chaque neurone calcule SA PROPRE somme pondérée :

   Neurone 1: w₁₁×0.5 + w₁₂×(-0.2) + ... + b₁ = 2.3   ← UN nombre
   Neurone 2: w₂₁×0.5 + w₂₂×(-0.2) + ... + b₂ = -0.7  ← UN nombre
   Neurone 3: w₃₁×0.5 + w₃₂×(-0.2) + ... + b₃ = 1.5   ← UN nombre
   ...
   Neurone 128: w₁₂₈×0.5 + ... + b₁₂₈ = 0.9           ← UN nombre

Output : [2.3, -0.7, 1.5, ..., 0.9]  (128 nombres)

Ensuite ces 128 nombres passent par BatchNorm, GELU, Dropout :

   Après Linear:    [2.3, -0.7, 1.5, ..., 0.9]
   Après BatchNorm: [1.1, -0.3, 0.8, ..., 0.5]  (normalisés)
   Après GELU:      [1.1,  0.0, 0.8, ..., 0.5]  (-0.3 → 0)
   Après Dropout:   [1.1,  0.0, 0.0, ..., 0.5]  (30% mis à 0)


ÉTAPE 10 : Pourquoi W est une MATRICE (et pas juste des nombres) ?
------------------------------------------------------------------

Dans un réseau fully-connected (MLP), CHAQUE neurone de sortie est connecté
à TOUS les neurones d'entrée. Il faut donc un poids pour CHAQUE connexion !

Exemple simple : 3 inputs → 2 outputs

   Input (3)              Output (2)
     x₁ ───w₁₁──→ ┐
     x₂ ───w₁₂──→ ├──→ y₁ = w₁₁×x₁ + w₁₂×x₂ + w₁₃×x₃ + b₁
     x₃ ───w₁₃──→ ┘

     x₁ ───w₂₁──→ ┐
     x₂ ───w₂₂──→ ├──→ y₂ = w₂₁×x₁ + w₂₂×x₂ + w₂₃×x₃ + b₂
     x₃ ───w₂₃──→ ┘

On a besoin de 6 poids (2×3) !
Ces 6 poids forment une matrice W de taille (2, 3) :

   W = [ w₁₁  w₁₂  w₁₃ ]   ← poids pour calculer y₁
       [ w₂₁  w₂₂  w₂₃ ]   ← poids pour calculer y₂

En notation matricielle : y = W @ x + b

Dans notre réseau Pacman :
- Linear(23, 128)  → W₁ : matrice 128×23 = 2,944 poids + 128 biais = 3,072 paramètres
- Linear(128, 64)  → W₂ : matrice 64×128 = 8,192 poids + 64 biais = 8,256 paramètres
- Linear(64, 32)   → W₃ : matrice 32×64 = 2,048 poids + 32 biais = 2,080 paramètres
- Linear(32, 5)    → W₄ : matrice 5×32 = 160 poids + 5 biais = 165 paramètres

TOTAL DES POIDS LINEAR : 13,573 paramètres

Avec les BatchNorm (γ et β pour chaque couche) :
- BatchNorm1d(128) : 128 × 2 = 256 paramètres
- BatchNorm1d(64)  : 64 × 2 = 128 paramètres
- BatchNorm1d(32)  : 32 × 2 = 64 paramètres

TOTAL AVEC BATCHNORM : 13,573 + 448 = 14,021 paramètres apprenables !


ÉTAPE 11 : Entraînement vs Évaluation
-------------------------------------

ENTRAÎNEMENT (model.train()) :
- On modifie les poids pour apprendre
- Dropout activé : désactive 30% des neurones aléatoirement
- On calcule la loss et les gradients
- On fait backward() et step()

ÉVALUATION (model.eval()) :
- On teste le réseau sans modifier les poids
- Dropout désactivé : utilise TOUS les neurones
- On calcule juste l'accuracy
- PAS de backward(), PAS de step()


ÉTAPE 12 : BatchNorm en détail - Que contiennent μ, σ², γ, β et ε ?
-------------------------------------------------------------------

C'est important de comprendre que ces paramètres sont des VECTEURS (pas des scalaires) !

Dans BatchNorm1d(128), voici ce qu'il y a concrètement :

1. **μ (mu)** - Moyenne du batch
   - Type : VECTEUR de taille (128,)
   - Contenu : [0.12, -0.35, 0.87, ..., -0.23]  (128 nombres)
   - Calculé sur le batch actuel : μ[i] = moyenne des valeurs du neurone i
   - PAS un paramètre apprenable (recalculé à chaque forward pass)

2. **σ² (sigma carré)** - Variance du batch
   - Type : VECTEUR de taille (128,)
   - Contenu : [0.45, 0.78, 0.23, ..., 0.91]  (128 nombres positifs)
   - Calculé sur le batch : σ²[i] = variance des valeurs du neurone i
   - PAS un paramètre apprenable

3. **ε (epsilon)** - Constante de stabilité
   - Type : SCALAIRE (un seul nombre)
   - Valeur : 1e-5 = 0.00001
   - Fixe, jamais modifié
   - Évite la division par zéro si σ² = 0

4. **γ (gamma)** - Paramètre d'échelle APPRENABLE
   - Type : VECTEUR de taille (128,)
   - Initialisé à : [1.0, 1.0, 1.0, ..., 1.0]  (128 fois 1)
   - APPRENABLE : modifié par l'optimizer pendant l'entraînement
   - Chaque neurone a son propre γ[i]

5. **β (beta)** - Paramètre de décalage APPRENABLE
   - Type : VECTEUR de taille (128,)
   - Initialisé à : [0.0, 0.0, 0.0, ..., 0.0]  (128 fois 0)
   - APPRENABLE : modifié par l'optimizer
   - Chaque neurone a son propre β[i]

Formule complète de BatchNorm :
   ẑ = (z - μ) / √(σ² + ε)        ← Normalisation
   output = γ × ẑ + β              ← Rééchelonnage

Exemple concret avec un batch de 256 exemples et 128 neurones :

   Input x : matrice (256, 128)  (256 exemples × 128 features)

   Calcul de μ (moyenne de chaque colonne) :
   μ[0] = moyenne de la colonne 0 sur les 256 exemples = 0.42
   μ[1] = moyenne de la colonne 1 = -0.15
   ...
   μ = [0.42, -0.15, ..., 0.18]  (128 nombres)

   Calcul de σ² (variance de chaque colonne) :
   σ²[0] = variance de la colonne 0 = 0.08
   σ²[1] = variance de la colonne 1 = 0.12
   ...
   σ² = [0.08, 0.12, ..., 0.09]  (128 nombres)

   Normalisation (pour CHAQUE neurone) :
   x_norm[:, i] = (x[:, i] - μ[i]) / √(σ²[i] + ε)

   Rééchelonnage :
   output[:, i] = γ[i] × x_norm[:, i] + β[i]

Résumé :
┌──────────┬──────────┬─────────┬──────────────┬────────────────────────┐
│ Variable │   Type   │  Taille │ Apprenable ? │         Rôle           │
├──────────┼──────────┼─────────┼──────────────┼────────────────────────┤
│    μ     │ Vecteur  │  (128,) │      ❌      │ Moyenne du batch       │
│    σ²    │ Vecteur  │  (128,) │      ❌      │ Variance du batch      │
│    ε     │ Scalaire │   (1,)  │      ❌      │ Constante = 0.00001    │
│    γ     │ Vecteur  │  (128,) │      ✅      │ Échelle (scale)        │
│    β     │ Vecteur  │  (128,) │      ✅      │ Décalage (shift)       │
└──────────┴──────────┴─────────┴──────────────┴────────────────────────┘


ÉTAPE 13 : Analogie finale pour tout comprendre
-----------------------------------------------

Imagine que tu apprends à tirer au basket :

- Forward pass = tu tires au panier
- Loss = distance entre le ballon et le panier (ton erreur)
- Gradients = "j'aurais dû tirer plus fort" ou "plus à gauche"
- Optimizer = tu ajustes ta technique pour le prochain tir
- Epochs = tu t'entraînes pendant des semaines

Au début tu rates beaucoup (loss élevée).
Après 150 jours d'entraînement, tu réussis 87% de tes tirs (accuracy = 87%).

C'est exactement pareil pour le réseau de neurones !


================================================================================
PARTIE 1 : Vue d'ensemble du projet
================================================================================

BUT DU PROJET
-------------
Apprendre à Pacman à imiter un expert en utilisant l'apprentissage supervisé.

On a :
- Un dataset de 15,018 exemples : (état du jeu, action de l'expert)
- Un expert qui joue très bien à Pacman

On veut :
- Entraîner un réseau de neurones à prédire quelle action l'expert aurait prise


LES 5 FICHIERS PRINCIPAUX
-------------------------

1. data.py
   → Transforme l'état du jeu en 23 nombres
   → Le réseau ne comprend que les nombres, pas les objets Python

2. architecture.py
   → Définit le cerveau du réseau : 23 → 128 → 64 → 32 → 5
   → 4 couches cachées avec GELU et Dropout

3. train.py
   → Entraîne le réseau sur 150 epochs
   → Sauvegarde le meilleur modèle

4. pacmanagent.py
   → Utilise le modèle entraîné pour jouer

5. write_submission.py
   → Génère le fichier CSV avec les prédictions pour Gradescope


STRUCTURE DES DONNÉES
---------------------

Entraînement :
- 15,018 exemples au total
- Split 80/20 : 12,014 pour l'entraînement, 3,004 pour le test
- Batch size 256 : on traite 256 exemples à la fois
- 47 batches par epoch

Test :
- Fichier séparé : pacman_test.pkl (pour Gradescope)
- Contient SEULEMENT des états de jeu (pas d'actions)
- On doit prédire l'action pour chaque état


================================================================================
PARTIE 2 : Les fichiers du projet
================================================================================

Structure du projet :

project2/
├── datasets/
│   ├── pacman_dataset.pkl    → Données d'entraînement (15,018 exemples)
│   └── pacman_test.pkl       → Données de test (pour Gradescope)
│
├── pacman_module/            → Moteur de jeu (NE PAS MODIFIER)
│   ├── game.py
│   ├── pacman.py
│   ├── layout.py
│   └── ...
│
├── data.py                   → Transforme GameState en 23 features
├── architecture.py           → Définit le réseau MLP
├── train.py                  → Entraîne le modèle
├── pacmanagent.py            → Agent qui utilise le modèle
├── run.py                    → Visualise le jeu
├── write_submission.py       → Génère le CSV pour Gradescope
│
├── pacman_model.pth          → Poids du modèle entraîné
└── submission.csv            → Prédictions pour Gradescope


================================================================================
PARTIE 3 : data.py - Transformer l'état du jeu en nombres
================================================================================

PROBLÈME
--------
Un réseau de neurones ne peut pas comprendre directement un GameState.
Il faut transformer l'état du jeu en nombres.


LES 23 FEATURES
---------------

Notre réseau prend 23 nombres en entrée. Voici ce qu'ils représentent :


1. POSITION DE PACMAN (2 features)
   [0] pac_x / maze_width    → Position X normalisée
   [1] pac_y / maze_height   → Position Y normalisée


2. INFORMATION SUR LE FANTÔME (4 features)
   [2] (ghost_x - pac_x) / maze_width   → Direction X vers le fantôme
   [3] (ghost_y - pac_y) / maze_height  → Direction Y vers le fantôme
   [4] distance_manhattan / max_dist    → Distance au fantôme
   [5] ghost_adjacent                   → 1 si fantôme à côté, 0 sinon


3. INFORMATION SUR LA NOURRITURE (4 features)
   [6] n_food / 50                      → Nombre de pastilles restantes
   [7] (food_x - pac_x) / maze_width    → Direction X vers la nourriture
   [8] (food_y - pac_y) / maze_height   → Direction Y vers la nourriture
   [9] distance_food / max_dist         → Distance à la nourriture


4. GÉOMÉTRIE DU LABYRINTHE (5 features)
   [10] distance_nord / maze_height     → Cases libres vers le nord
   [11] distance_sud / maze_height      → Cases libres vers le sud
   [12] distance_est / maze_width       → Cases libres vers l'est
   [13] distance_ouest / maze_width     → Cases libres vers l'ouest
   [14] is_corner                       → 1 si coin (≤2 directions), 0 sinon


5. NIVEAU DE DANGER (3 features)
   [15] danger_level                    → 1 / max(dist_ghost, 0.5)
   [16] ghost_blocks_food               → 1 si fantôme entre Pacman et food
   [17] escape_options                  → Nombre de directions / 4


6. ACTIONS LÉGALES (5 features)
   [18] legal_north   → 1 si on peut aller au nord, 0 sinon
   [19] legal_south   → 1 si on peut aller au sud, 0 sinon
   [20] legal_east    → 1 si on peut aller à l'est, 0 sinon
   [21] legal_west    → 1 si on peut aller à l'ouest, 0 sinon
   [22] legal_stop    → 1 si on peut s'arrêter, 0 sinon


POURQUOI NORMALISER ?
--------------------

Sans normalisation :
- Position X : entre 0 et 20
- Position Y : entre 0 et 20
- Distance : entre 0 et 40
- Legal flags : 0 ou 1

Problème : les grandes valeurs (positions, distances) dominent les petites (flags).
Le réseau apprend mal.

Avec normalisation :
- Tout est entre 0 et 1
- Toutes les features ont la même importance
- Le réseau apprend beaucoup mieux !


COMMENT ON TROUVE LA NOURRITURE LA PLUS PROCHE ?
------------------------------------------------

1. On récupère toutes les positions de nourriture
   food_positions = [(5, 3), (7, 8), (2, 4), ...]

2. On calcule la distance Manhattan à CHAQUE nourriture
   distance = |pac_x - food_x| + |pac_y - food_y|

3. On trouve laquelle est la plus proche
   min_distance = min(distances)

4. On calcule la direction vers cette nourriture
   direction_x = food_x - pac_x
   direction_y = food_y - pac_y


COMMENT ON CALCULE LA DISTANCE JUSQU'AU MUR ?
---------------------------------------------

La fonction dist_until_wall(x, y, dx, dy) compte combien de cases on peut
avancer dans une direction avant de toucher un mur.

Exemple visuel :

   # # # # # # #
   # . . . . . #
   # # P . . . #  ← Pacman en (2, 2)
   # # # . . . #
   # # # # # # #

   dist_until_wall(2, 2,  1, 0) = 3  (3 cases libres vers l'est)
   dist_until_wall(2, 2, -1, 0) = 0  (mur immédiat à l'ouest)
   dist_until_wall(2, 2,  0, 1) = 1  (1 case libre vers le nord)


CONVERSION DES ACTIONS EN INDICES
---------------------------------

Le réseau ne comprend pas les objets Python comme Directions.NORTH.
On doit convertir en indices (nombres) :

ACTION_TO_INDEX = {
   Directions.NORTH: 0,
   Directions.SOUTH: 1,
   Directions.EAST: 2,
   Directions.WEST: 3,
   Directions.STOP: 4
}

INDEX_TO_ACTION = {0: NORTH, 1: SOUTH, 2: EAST, 3: WEST, 4: STOP}

Pendant l'entraînement :
   Expert joue EAST → converti en indice 2 → Le réseau apprend à prédire 2

Pendant l'inférence :
   Réseau prédit [0.05, 0.1, 0.75, 0.08, 0.02]
   → argmax = 2
   → reconverti en EAST


================================================================================
PARTIE 4 : architecture.py - Le cerveau du réseau
================================================================================

CHOIX D'ARCHITECTURE : POURQUOI UN MLP ?
----------------------------------------

MLP = Multi-Layer Perceptron = réseau de neurones fully-connected

On n'utilise PAS de CNN (Convolutional Neural Network) parce que :
- Les CNN sont faits pour les images 2D (pixels voisins sont liés)
- Notre input est un vecteur 1D de 23 nombres
- Pas de relation spatiale entre les features
- Un MLP simple est le bon choix


STRUCTURE DU RÉSEAU
-------------------

23 inputs → 128 → 64 → 32 → 5 outputs

Input Layer:     23 neurones (nos 23 features)
Hidden Layer 1:  128 neurones
Hidden Layer 2:  64 neurones
Hidden Layer 3:  32 neurones
Output Layer:    5 neurones (les 5 actions)

Total : 14,021 paramètres apprenables (incluant les biais et BatchNorm) !


PATTERN DE CHAQUE COUCHE CACHÉE
-------------------------------

Pour chaque couche cachée, on applique 4 opérations dans l'ordre :

1. Linear(in, out)
   → Transformation linéaire : y = W @ x + b
   → Calcule les combinaisons pondérées

2. BatchNorm1d(out)
   → Normalise les valeurs (moyenne=0, variance=1)
   → Stabilise l'entraînement

3. GELU()
   → Fonction d'activation : f(x) = x · Φ(x) où Φ est la distribution gaussienne
   → Atténue les valeurs négatives avec une courbe lisse
   → Casse la linéarité (permet d'apprendre des fonctions complexes)

4. Dropout(0.3)
   → Éteint aléatoirement 30% des neurones pendant l'entraînement
   → Évite l'overfitting (empêche le réseau de mémoriser)


POURQUOI GELU ?
--------------

GELU est l'activation standard pour les MLPs :
- Simple : f(x) = x · Φ(x) où Φ est la distribution gaussienne
- Rapide à calculer
- Résout le problème du vanishing gradient
- Permet une convergence rapide

Alternative : GELU (plus smooth), mais GELU fonctionne très bien ici.


POURQUOI BATCHNORM ?
-------------------

Sans BatchNorm, l'entraînement était instable.
BatchNorm normalise les valeurs entre les couches.

Avantages :
- Stabilise les gradients
- Permet d'utiliser un learning rate plus élevé
- Convergence plus rapide


POURQUOI DROPOUT ?
-----------------

Dropout = régularisation pour éviter l'overfitting

Dropout(0.3) signifie :
- Pendant l'entraînement : éteint 30% des neurones aléatoirement
- Pendant l'évaluation : utilise TOUS les neurones

Pourquoi ça marche ?
- Force le réseau à ne pas trop dépendre de certains neurones
- Le réseau apprend des patterns plus robustes
- Généralise mieux sur de nouveaux exemples

Valeur optimale : 0.3 (testé empiriquement)
- Trop de dropout (0.5) : underfitting
- Pas assez (0.1) : overfitting


PAS D'ACTIVATION SUR LA DERNIÈRE COUCHE
---------------------------------------

La dernière couche est juste Linear(32, 5), sans GELU.

Pourquoi ?
- On veut des valeurs brutes (logits) : [-2.1, 0.5, 3.2, 1.0, -0.3]
- CrossEntropyLoss fait le Softmax automatiquement
- Pas besoin de mettre Softmax dans le réseau


CODE SIMPLIFIÉ
--------------

def __init__(self):
    layers = []

    # Couche 1 : 23 → 128
    layers.append(nn.Linear(23, 128))
    layers.append(nn.BatchNorm1d(128))
    layers.append(nn.GELU())
    layers.append(nn.Dropout(0.3))

    # Couche 2 : 128 → 64
    layers.append(nn.Linear(128, 64))
    layers.append(nn.BatchNorm1d(64))
    layers.append(nn.GELU())
    layers.append(nn.Dropout(0.3))

    # Couche 3 : 64 → 32
    layers.append(nn.Linear(64, 32))
    layers.append(nn.BatchNorm1d(32))
    layers.append(nn.GELU())
    layers.append(nn.Dropout(0.3))

    # Couche de sortie : 32 → 5
    layers.append(nn.Linear(32, 5))

    self.net = nn.Sequential(*layers)
    self.criterion = nn.CrossEntropyLoss()


================================================================================
PARTIE 5 : train.py - Apprendre au réseau
================================================================================

PIPELINE D'ENTRAÎNEMENT
-----------------------

1. Charger le dataset (15,018 exemples)
2. Split train/test 80/20 (12,014 train / 3,004 test)
3. Créer les DataLoaders avec batch_size=256
4. Entraîner pendant 150 epochs
5. Évaluer sur le test set à chaque epoch
6. Sauvegarder le meilleur modèle


HYPERPARAMÈTRES
--------------

batch_size = 256
- Traite 256 exemples à la fois
- Gradients plus stables (moyenne sur 256 exemples)
- Plus efficace pour le GPU

epochs = 150
- Répète l'entraînement 150 fois sur tout le dataset
- Suffisant pour converger complètement
- Le meilleur modèle est généralement vers epoch 120-130

learning_rate = 8e-4 (0.0008)
- Légèrement élevé pour converger plus vite
- Pas trop élevé pour rester stable

test_ratio = 0.2
- 20% des données pour tester
- 80% pour entraîner


LA LOSS FUNCTION : CROSSENTROPYLOSS
-----------------------------------

CrossEntropyLoss est LA loss standard pour la classification multi-classe.

Comment ça marche ?

ÉTAPE 1 : Le réseau produit des logits
   [2.1, 0.5, 3.2, 1.0, 0.3]

ÉTAPE 2 : Softmax transforme en probabilités
   [0.18, 0.04, 0.54, 0.06, 0.03]
   (somme = 1.0)

ÉTAPE 3 : On prend le log des probabilités
   [log(0.18), log(0.04), log(0.54), log(0.06), log(0.03)]

ÉTAPE 4 : On sélectionne la bonne action et on calcule -log(proba)
   Si la bonne action est NORTH (indice 0) :
   Loss = -log(0.18) = 1.71

ÉTAPE 5 : On fait la moyenne sur tout le batch
   Loss_batch = moyenne de toutes les losses

PyTorch fait TOUT ça automatiquement avec CrossEntropyLoss() !


L'OPTIMIZER : ADAM
-----------------

Adam (Adaptive Moment Estimation) est l'optimizer standard en deep learning.

Pourquoi Adam ?
- Adapte le learning rate pour chaque poids individuellement
- Converge plus vite que Gradient Descent classique
- Plus stable (moins de variations)



BOUCLE D'ENTRAÎNEMENT COMPLÈTE
------------------------------

```python
for epoch in range(150):
    model.train()  # Mode entraînement (dropout activé)

    for features, actions in train_loader:
        # 1. Forward pass
        loss = model.loss(features, actions)

        # 2. Backward pass
        optim.zero_grad()  # Efface les anciens gradients
        loss.backward()    # Calcule les nouveaux gradients
        optim.step()       # Met à jour les poids

    # Évaluation sur le test set
    model.eval()  # Mode évaluation (dropout désactivé)
    accuracy = evaluate(model, test_loader)

    # Sauvegarde du meilleur modèle
    if accuracy > best_accuracy:
        best_accuracy = accuracy
        torch.save(model.state_dict(), 'pacman_model.pth')

    print(f"Epoch {epoch}: Accuracy = {accuracy:.2f}%")
```


CHECKPOINTING : SAUVEGARDER LE MEILLEUR MODÈLE
----------------------------------------------

À chaque epoch, on évalue l'accuracy sur le test set.
Si c'est la meilleure accuracy jusqu'à maintenant, on sauvegarde le modèle.

Pourquoi ?
- Le dernier modèle (epoch 150) n'est pas toujours le meilleur
- Il peut avoir overfitté (mémorisé les données d'entraînement)
- Le meilleur modèle est celui qui généralise le mieux (meilleure test accuracy)

Le modèle est sauvegardé dans pacman_model.pth


RÉSULTATS TYPIQUES
-----------------

Epoch 1:   Accuracy ≈ 60%  (commence aléatoire)
Epoch 50:  Accuracy ≈ 82%
Epoch 100: Accuracy ≈ 86%
Epoch 120: Accuracy ≈ 87.5%  ← Meilleur modèle
Epoch 150: Accuracy ≈ 87.2%  (légère baisse = overfitting)

Pourquoi l'accuracy plafonne à ~87-88% ?
- Dans certaines situations, plusieurs actions sont également bonnes
- Le réseau peut choisir une action différente de l'expert, mais tout aussi valide
- C'est normal et ne veut pas dire que le modèle est mauvais


================================================================================
PARTIE 6 : write_submission.py - Générer les prédictions
================================================================================

OBJECTIF
--------
Générer un fichier submission.csv avec les prédictions pour Gradescope.


DIFFÉRENCE ENTRE TRAIN SET ET TEST SET
--------------------------------------

Train set (pacman_dataset.pkl) :
- Contient : (GameState, action) paires
- 15,018 exemples
- On connaît l'action de l'expert
- Utilisé pour entraîner le réseau

Test set (pacman_test.pkl) :
- Contient : SEULEMENT des GameState (pas d'actions !)
- Nombre d'exemples inconnu
- On doit PRÉDIRE l'action
- Utilisé pour Gradescope


ÉTAPE 1 : INITIALISATION
------------------------

```python
def __init__(self, test_set_path, model_path):
    # Charger le test set
    with open(test_set_path, 'rb') as f:
        self.test_set = pickle.load(f)

    # Charger le modèle
    self.model = PacmanNetwork()
    self.model.load_state_dict(torch.load(model_path))

    # Mode évaluation (dropout désactivé)
    self.model.eval()
```


ÉTAPE 2 : PRÉDICTION
--------------------

Pour chaque état du test set, on fait une prédiction :

```python
def predict_on_testset(self):
    actions = []

    for state in self.test_set:
        # 1. Convertir GameState en tensor (23 features)
        x = state_to_tensor(state)

        # 2. Ajouter dimension batch (1, 23)
        x = x.unsqueeze(0)

        # 3. Désactiver les gradients (on ne fait que de l'inférence)
        with torch.no_grad():
            # 4. Forward pass
            logits = self.model(x)

            # 5. Prendre l'action avec le score le plus élevé
            pred_index = logits.argmax(dim=1).item()

            # 6. Convertir l'indice en action
            action = INDEX_TO_ACTION[pred_index]

            # 7. Ajouter à la liste
            actions.append(action)

    return actions
```


ÉTAPE 3 : ÉCRITURE DU CSV
-------------------------

```python
def write_csv(self, actions, file_name="submission"):
    # Créer un DataFrame pandas
    df = pd.DataFrame({'ACTION': actions})

    # Écrire dans submission.csv
    df.to_csv(file_name + '.csv', index=False)
```

Format du CSV :
```
ACTION
North
East
East
West
South
...
```


POINTS IMPORTANTS
----------------

1. torch.no_grad()
   - Désactive le calcul des gradients
   - Économise de la mémoire
   - Accélère l'inférence

2. model.eval()
   - Désactive le dropout
   - Utilise TOUS les neurones
   - Prédictions déterministes (toujours les mêmes pour un état donné)

3. unsqueeze(0)
   - Ajoute une dimension batch
   - (23,) devient (1, 23)
   - Le modèle attend toujours un batch (même d'un seul exemple)

4. argmax(dim=1)
   - Prend l'indice du maximum
   - [2.1, 0.5, 3.2, 1.0, 0.3] → indice 2 (EAST)

5. ORDRE IMPORTANT
   - Les prédictions doivent être dans le MÊME ORDRE que le test set
   - On ne peut pas trier ou mélanger les prédictions


UTILISATION
----------

```python
# Créer le writer
writer = SubmissionWriter(
    test_set_path="datasets/pacman_test.pkl",
    model_path="pacman_model.pth"
)

# Générer les prédictions
predictions = writer.predict_on_testset()

# Écrire le CSV
writer.write_csv(predictions)
```

Résultat : fichier submission.csv créé avec toutes les prédictions.


================================================================================
PARTIE 7 : Questions fréquentes (FAQ)
================================================================================

Q: Pourquoi un MLP et pas un CNN ?
-----------------------------------
R: Les CNN sont faits pour les images 2D où les pixels voisins sont liés.
   Notre input est un vecteur 1D de 23 nombres sans relation spatiale.
   Un MLP est le bon choix pour ce type de données.


Q: Pourquoi normaliser les features ?
--------------------------------------
R: Les réseaux de neurones convergent mieux quand toutes les features
   sont dans la même échelle (~[0, 1]).
   Sans normalisation :
   - Position X : 0-20
   - Distance : 0-40
   - Legal flags : 0-1
   Les grandes valeurs domineraient les petites.
   Avec normalisation, tout est ~[0, 1] et le réseau apprend bien mieux.


Q: Pourquoi GELU au lieu de GELU ?
-----------------------------------
R: GELU est plus simple et rapide : f(x) = x · Φ(x) où Φ est la distribution gaussienne
   GELU est plus smooth (gradients plus fluides), mais GELU fonctionne
   très bien pour ce problème et converge rapidement.
   GELU est l'activation standard dans les MLPs classiques.


Q: Pourquoi BatchNorm ?
------------------------
R: Sans BatchNorm, l'entraînement était instable.
   BatchNorm normalise les valeurs entre couches pour stabiliser les gradients.
   Permet d'utiliser un learning rate plus élevé et convergence plus rapide.


Q: Pourquoi CrossEntropyLoss ?
-------------------------------
R: C'est LA loss standard pour la classification multi-classe.
   Elle combine Softmax + Log + Sélection + Moyenne en une seule opération.
   Numériquement stable et efficace.


Q: Pourquoi 150 epochs ?
-------------------------
R: Optimisé empiriquement.
   - 50 epochs : pas assez, accuracy ~82%
   - 100 epochs : bien, accuracy ~86%
   - 150 epochs : optimal, accuracy ~87-88%
   - 200 epochs : overfitting, accuracy baisse
   Le meilleur modèle est généralement vers epoch 120-130.


Q: Pourquoi dropout = 0.3 ?
----------------------------
R: Balance entre régularisation et capacité du réseau.
   - dropout = 0.1 : risque d'overfitting
   - dropout = 0.3 : optimal (sweet spot)
   - dropout = 0.5 : underfitting
   Testé empiriquement.


Q: Pourquoi batch_size = 256 ?
-------------------------------
R: - Gradients plus stables (moyenne sur 256 exemples)
   - Plus efficace pour le GPU
   - Bon compromis entre vitesse et stabilité
   - Batch size plus petit (32) : gradients instables
   - Batch size plus grand (512) : moins de mises à jour par epoch


Q: Comment un neurone traite-t-il un batch ?
---------------------------------------------
R: Chaque neurone traite TOUS les exemples du batch en parallèle.

   Exemple avec batch_size=3 et le neurone 0 de la couche Linear(23, 128):

   - Il reçoit 3 vecteurs d'entrée (x₀, x₁, x₂) de 23 valeurs chacun
   - Il a ses propres poids w₀ (23 valeurs) et biais b₀
   - Il calcule 3 sorties (une par exemple):
     * z₀,₀ = x₀ · w₀ + b₀ = 2.3
     * z₁,₀ = x₁ · w₀ + b₀ = 0.9
     * z₂,₀ = x₂ · w₀ + b₀ = -1.1

   - Résultat: le neurone 0 produit une COLONNE de 3 valeurs [2.3, 0.9, -1.1]

   En notation matricielle: X (3, 23) @ W^T (23, 128) → Z (3, 128)
   Chaque colonne de Z correspond aux sorties d'un neurone sur le batch.


Q: Comment gérer les actions illégales ?
-----------------------------------------
R: Dans pacmanagent.py, on trie les prédictions par probabilité
   et on prend la première action qui est dans la liste des actions légales.
   Le réseau apprend à éviter les actions illégales car il a les
   legal_flags dans ses features d'entrée.


Q: Pourquoi l'accuracy plafonne à ~87-88% ?
--------------------------------------------
R: Dans ~10-15% des situations, plusieurs actions sont également bonnes.
   Exemple : fantôme loin, plusieurs chemins vers la nourriture.
   Le réseau peut choisir une action différente de l'expert, mais tout
   aussi valide. L'accuracy mesure seulement si c'est EXACTEMENT la même
   action que l'expert, pas si c'est une bonne action.


Q: Est-ce que le modèle fonctionne sur différents labyrinthes ?
----------------------------------------------------------------
R: Oui ! Les features sont adaptatives :
   - Positions normalisées par maze_width et maze_height
   - Distances normalisées par la taille du labyrinthe
   - legal_actions s'adapte automatiquement aux murs
   - dist_until_wall détecte les murs dans chaque direction

   Le modèle a appris des patterns généraux (fuir les fantômes, aller
   vers la nourriture, éviter les coins) pas juste à mémoriser un labyrinthe.


Q: Comment convertir les actions en indices ?
----------------------------------------------
R: Le réseau ne comprend que les nombres, pas les objets Python.
   On crée deux mappings :

   ACTION_TO_INDEX = {
      Directions.NORTH: 0,
      Directions.SOUTH: 1,
      Directions.EAST: 2,
      Directions.WEST: 3,
      Directions.STOP: 4
   }

   INDEX_TO_ACTION = {0: NORTH, 1: SOUTH, 2: EAST, 3: WEST, 4: STOP}

   Entraînement : Expert joue EAST → indice 2 → Réseau apprend à prédire 2
   Inférence : Réseau prédit 2 → reconverti en EAST


Q: Quelle est la feature la plus importante ?
----------------------------------------------
R: Les features de danger sont les plus importantes :
   - danger_level : gradient de danger (1 / distance)
   - ghost_blocks_food : fantôme entre Pacman et la nourriture ?
   - escape_options : combien de directions pour fuir ?

   Sans ces features, le modèle avait du mal à éviter les fantômes.
   Avec ces features, accuracy +5%.


Q: Pourquoi utiliser Adam au lieu de SGD ?
-------------------------------------------
R: Adam adapte automatiquement le learning rate pour chaque poids.
   - SGD : même learning rate pour tous les poids
   - Adam : learning rate adaptatif et intelligent

   Résultat : converge plus vite et de manière plus stable.
   C'est l'optimizer standard en deep learning.


================================================================================
Nouvelle tentative d'explication
================================================================================
──────────────────────────────────────────────────────────────────────────────
PIPELINE (si batch = 3) : GameState → Features → 3 hiddens → Logits → Action
──────────────────────────────────────────────────────────────────────────────
LE DATALOADER DONNE UN BATCH 3 gamestates

features X : matrice (3, 23)
3 GameState transformés en 23 nombres chacun

actions = y : vecteur (3,)


──────────────────────────────────────────────────────────────────────────────
BLOC 1 — TRAIN (APPRENDRE : loss + backward + update)
──────────────────────────────────────────────────────────────────────────────
Objectif TRAIN : MODIFIER les poids pour réduire l'erreur.

Étape 1 — FORWARD Si X : (3, 23)

VISUALISATION : Les neurones sont à la VERTICALE (colonnes)
                Les exemples du batch sont à l'HORIZONTALE (lignes)

   X = matrice (3, 23)
       3 lignes (3 GameStates) × 23 colonnes (23 FEATURES, pas des neurones!)

                  feature 0   feature 1   feature 2   feature 3   ...  feature 22
                      ↓           ↓           ↓           ↓       ...      ↓
   GameState 0  →   [0.5,       0.3,        0.2,        0.1,      ...     0.9]
   GameState 1  →   [0.1,       0.8,        0.4,        0.2,      ...     0.3]
   GameState 2  →   [0.7,       0.2,        0.6,        0.3,      ...     0.5]


Linear(23→128) : (3, 23) -> (3, 128)
   Calcul : z = X @ W^T + b
   Crée les PREMIERS VRAIS NEURONES : 128 neurones à partir des 23 features

   z = matrice (3, 128)
       3 lignes (3 GameStates) × 128 colonnes (128 NEURONES)

                      h0         h1         h2        h3       ...   h127
                      ↓          ↓          ↓          ↓          ...  ↓
   GameState 0  →   [2.3,      -0.7,      1.5,       0.2,    ...     1.8]
   GameState 1  →   [0.9,       1.2,     -0.3,       0.8,    ...     0.5]
   GameState 2  →   [-1.1,      0.5,      2.0,      -0.5,    ...     1.2]


BatchNorm1d(128) : (3, 128) -> (3, 128)
   TRAIN: calcule μ et σ² pour CHAQUE NEURONE (chaque colonne verticale)

   AVANT BatchNorm (sortie de Linear) :
                     h0        h1         h2         h3         ...  h127
                     ↓          ↓          ↓          ↓          ...  ↓
   GameState 0  →   [2.3,      -0.7,      1.5,       0.2,    ...     1.8]
   GameState 1  →   [0.9,       1.2,     -0.3,       0.8,    ...     0.5]
   GameState 2  →   [-1.1,      0.5,      2.0,      -0.5,    ...     1.2]

   Pour h0 (colonne 0) :
      Valeurs sur le batch : [2.3, 0.9, -1.1]
      μ[0] = (2.3 + 0.9 + (-1.1)) / 3 = 0.70
      σ²[0] = variance([2.3, 0.9, -1.1]) = 2.45

   Pour h1 (colonne 1) :
      Valeurs sur le batch : [-0.7, 1.2, 0.5]
      μ[1] = (-0.7 + 1.2 + 0.5) / 3 = 0.33
      σ²[1] = variance([-0.7, 1.2, 0.5]) = 0.82

   Donc : μ =vecteur = [0.70, 0.33, 1.07, ...128 valeurs] (un μ par neurone)
          σ² =vecteur = [2.45, 0.82, 0.55, ...128 valeurs] (un σ² par neurone)

   Normalisation de CHAQUE colonne (neurone) :
      Pour chaque neurone Hj, on normalise ses 3 valeurs avec μ[j] et σ²[j]

   Puis rééchelonnage : z_final = γ * z_norm + β

   APRÈS BatchNorm (normalisé + rééchelonné) :
                     h0        h1          h2        h3          ... h127
                     ↓          ↓          ↓          ↓          ...  ↓
   GameState 0  →   [1.2,      -0.5,      0.8,       0.1,    ...     0.9]
   GameState 1  →   [0.1,       0.9,     -0.2,       0.5,    ...     0.3]
   GameState 2  →   [-1.3,      0.3,      1.4,      -0.6,    ...     0.7]


GELU : (3, 128) -> (3, 128)
   Applique GELU(x) = x · Φ(x) sur CHAQUE neurone, pour CHAQUE exemple

                 neurone 0  neurone 1  neurone 2  neurone 3  ...
                     ↓          ↓          ↓          ↓
   GameState 0  →   [1.2,      0.0,       0.8,       0.1,    ...]
   GameState 1  →   [0.1,      0.9,       0.0,       0.5,    ...]
   GameState 2  →   [0.0,      0.3,       1.4,       0.0,    ...]
                     ✓          ✗          ✓          ✓
                  (positif)  (négatif   (positif)  (positif)
                              → 0)


Dropout(0.3) : (3, 128) -> (3, 128)
   TRAIN: désactive aléatoirement 30% des neurones (met la colonne entière à 0? NON!)
   En fait: met 30% des VALEURS à 0 (élément par élément)

                 neurone 0  neurone 1  neurone 2  neurone 3  ...
                     ↓          ↓          ↓          ↓
   GameState 0  →   [1.2,      0.0,       0.0,       0.1,    ...]
   GameState 1  →   [0.1,      0.0,       0.0,       0.5,    ...]
   GameState 2  →   [0.0,      0.3,       1.4,       0.0,    ...]



Sortie Linear(32→5) : (3, 32) -> (3, 5)
   On passe de 32 neurones à 5 neurones de sortie (les 5 actions)
   logits = matrice (3, 5)

                  NORTH    SOUTH    EAST     WEST     STOP
                    ↓        ↓        ↓        ↓        ↓
   GameState 0  →  [2.1,    0.5,    -0.3,    1.8,     0.2]
   GameState 1  →  [1.2,   -0.5,     2.3,    0.1,    -0.8]
   GameState 2  →  [0.3,    1.5,     0.7,   -1.2,     0.9]

Interprétation (on cherche le max sur chaque ligne) :
   GameState 0 : neurone NORTH = 2.1 (max) → prédiction = NORTH
   GameState 1 : neurone EAST = 2.3 (max)  → prédiction = EAST
   GameState 2 : neurone SOUTH = 1.5 (max) → prédiction = SOUTH


Étape 2 — LOSS (mesurer l'erreur)

   For multi-class classification with C classes:
   L = - (1/N) Σᵢ log(softmax(logitsᵢ)[yᵢ])

   Where:
   - N = batch size
   - logitsᵢ = predicted logits for example i
   - yᵢ = true class label for example i
   - softmax(z)ⱼ = exp(zⱼ) / Σₖ exp(zₖ)

   CONCRETE EXAMPLE:
   Predicted logits for example 1: [2.1, -0.5, 1.3, 0.2, -1.1]
   True action: 0 (go North)

   Softmax:
   exp([2.1, -0.5, 1.3, 0.2, -1.1]) / sum(exp(.C..))
   ≈ [0.65, 0.05, 0.29, 0.10, 0.03]

   Loss for this example:
   -log(0.65) ≈ 0.43

   If prediction was perfect (prob=1.0 for correct class):
   -log(1.0) = 0 (minimum loss)

   If prediction was terrible (prob=0.01 for correct class):
   -log(0.01) ≈ 4.6 (high loss)

   The loss measures: "How confident was the model in the CORRECT answer?"





Étape 3 — BACKWARD (calculer les gradients)

loss.backward() calcule les gradients de TOUS les paramètres θ:
ces gradients servent à savoir comment bouger chaque paramètre pour réduire la loss



Étape 4 — UPDATE (mettre à jour les poids) = ADAM 

optim.step() modifie les paramètres θ pour diminuer la loss

   Comment ça marche ?
   1. Calcule la moyenne des gradients récents (momentum)
   2. Calcule la variance des gradients récents
   3. Ajuste le learning rate selon ces statistiques

   Résultat :
   - GRANDS pas quand le gradient est stable et fort (on est loin du minimum)
   - PETITS pas quand le gradient est instable ou faible (on est proche du minimum)







──────────────────────────────────────────────────────────────────────────────
BLOC 2 — EVAL (MESURER : accuracy, pas d’apprentissage)
──────────────────────────────────────────────────────────────────────────────

Objectif EVAL : MESURER sans modifier les poids.

Étape 1 — PASSER EN MODE EVAL

model.eval() change le comportement de certains modules:

   Dropout en eval: il est off

   BatchNorm:n’utilise plus μ/σ² du batch pour un neuronne 


Étape 2 — FORWARD SANS GRADIENTS
   outputs = model.forward(features)   # FORWARD - Output=logits


Étape 3 — PRÉDICTION

_, predicted = torch.max(outputs, dim=1) 
   Regarde le max ds logits c'est la direction prédie


Étape 4 — ACCURACY

accuracy = nombre de bonnes prédictions / 3
